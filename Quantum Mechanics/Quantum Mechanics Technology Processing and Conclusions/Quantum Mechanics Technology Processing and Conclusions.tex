\documentclass{article}
\newcommand{\singleline}{\hrule height 0.8pt}
\newcommand{\mydate}{Otctober 2, 2025 - \today}
\newcommand{\mytitle}{Quantum Mechanics Technology Processing and Conclusions}
\title{\textbf{\mytitle}}
\author{Jiete XUE}
\date{\mydate}
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{}
\fancyhead[L]{\leftmark}
\fancyfoot[C]{\thepage}
\usepackage[perpage]{footmisc}
\usepackage{tocloft}
\renewcommand{\cftsecleader}{\cftdotfill{\cftdotsep}}
\usepackage{tcolorbox}
\definecolor{mlv}{RGB}{40, 137, 124}
\usepackage[colorlinks=true, linkcolor=mlv, citecolor=red, urlcolor=mlv, filecolor=mlv]{hyperref}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathrsfs}
\usepackage{physics}
\usepackage{tikz}
\usepackage{tcolorbox}
\usepackage{graphicx}
\graphicspath{{./}{images/}}
\usepackage{float}

%% 右矢
%\ket{\psi}          % 输出：|ψ⟩
%\ket{\psi(t)}       % 输出：|ψ(t)⟩
%
%% 左矢
%\bra{\phi}          % 输出：⟨φ|
%
%% 期望值
%\expval{\hat{A}}    % 输出：⟨Â⟩
%\expval{\hat{A}}{\psi}  % 输出：⟨ψ|Â|ψ⟩
%
%% 对易子
%\comm{\hat{A}}{\hat{B}}  % 输出：[Â, B̂]

\usepackage{pdfpages}

\newtheoremstyle{1}{}{}{}{}{\bfseries}{}{\newline}{}
\newtheoremstyle{2}{}{}{}{}{\bfseries}{.}{\newline}{}
\theoremstyle{1}
\newtheorem{problem}{Problem}[section]
\newtheorem{theorem}[problem]{Theorem}
\newtheorem{notation}{Notation}[section]
\usepackage{chngcntr}
\counterwithin{equation}{section}
\counterwithin{figure}{section}
\newcommand{\pa}{\partial}
\newcommand{\ii}{\mathrm{i}}
\newcommand{\ee}{\mathrm{e}}

\begin{document}
\maketitle
\thispagestyle{empty}
\newpage
\pagenumbering{roman}
\setcounter{page}{1}
\tableofcontents
\newpage
\pagenumbering{arabic}
\setcounter{page}{1}





\section{Quantization}
\begin{equation}\label{eq 1.1}
    \oint p\dd{q}=n h +C,\ n=1,2,3,\dots 
\end{equation}
This is not always right, but it's a good approximation. 
\section{Heisenberg's Breakthrough}
Heisenberg use matrices to represent quantum states.\footnote{Here use the similar notation $x(t)$ and $x$, but they represent different things. In some cases, we will ignore $(t)$ but still represent $x(t)$ for convenience.}
\begin{equation}
    x_{n,m}(t)=x_{n,m}\ee^{\ii\omega_{n,m}t}.
\end{equation}
With the \textbf{Ritz combination law}\footnote{You can imagine a electron moving from state $m$ to state $n$ passing state $k$.}
\begin{equation}
    \omega_{n,m}=\omega_{n,k}+\omega_{k,m},
\end{equation}
we can calculate $x^2$ like
\begin{equation}
    \left(x^2\right)_{n,m}\ee^{\ii\omega_{n,m}t}=\sum_{k}x_{n,k}(t)x_{k,m}(t)=\sum_{k}x_{n,k}x_{k,m}\ee^{\ii\omega_{n,m}t}.
\end{equation}

\singleline
\begin{problem}[Harmonic Oscillator]
\quad 
By solving this example, we can get how to deal with the problems in quantum situations.
The equation of the harmonic oscillator in the classic mechanics is:
\begin{equation}
    \ddot{x}+\omega_0^2x=0.
\end{equation}
We can deduce that 
\begin{equation}
    \left(\omega^2_0-\omega_{n,m}^2\right)x_{n,m}(t)=0.
\end{equation}
Their's a strange assumption, we may treat\footnote{Their must exists a $\omega_{n,m}=\omega_0$, or $x_{n,m}=0$, or the physics phenomenon can not be detected.} $\omega_{n,n+1}$ as $\omega_0$, then only for those $x_{n,n\pm1}$ can not be zero. Then we can use \eqref{eq 1.1} to obtain other information. (Use $t$ as parameter to do the integration.)
\newline
Only when $n=m$, the integration of 
\begin{equation}
    -m \omega_{n,k}\omega_{k,m}x_{n,k}x_{k,m}\ee^{\ii\omega_{n,m}t}
\end{equation}
 in a period can not be zero.\footnote{$\omega_{n,n}=0.$} Then we obtain \footnote{Here I used f-sum rule exactly. But I think there's some details need to check, about where the $\frac{1}{2}$ comes from. It appear as $C$ in quantization condition.}
 \begin{equation}
    \frac{\hbar}{2m}=\omega_0\left[\left|x_{n+1,n}\right|^2-\left|x_{n,n-1}\right|^2\right].
 \end{equation}
\end{problem}
\singleline


\section{ De Broglie's \& Schrödinger's Equation}
De Broglie use 
\begin{equation}
    \frac{\dd{\omega}}{\dd{k}}=v_g=\frac{pc^2}{E}
\end{equation}
and 
\begin{equation}
    E^2=p^2c^2+m_0^2c^4
\end{equation}
with 
\begin{equation}
    E=\hbar\omega
\end{equation}
to derive that 
\begin{equation}
    p=\hbar k.
\end{equation}
It is wave-like. Debye told to Schrödinger that: If it is a wave, then you can try to get a wave equation to describe it. 
\newline
If we consider a plane wave, the it take the form of 
\begin{equation}
    \psi\sim \ee^{\frac{\ii}{\hbar}\left(px-Et\right)}.
\end{equation}
The exponent is similar to $S$: the action. So we can let $\psi=\ee^{\ii S/\hbar}$, and try to explore what we can get after plugging  it into the Hamilton equation.
\begin{equation}
    \frac{\hbar^2}{2m}\left(\nabla \psi\right)^2+\left(E-V(r)\right)\psi^2=0.
\end{equation}
We want a linear equation. Then we let $\nabla$ act on it, and suppose $V(r)$ is smooth at the $\hbar$ scale. Then we get
\begin{equation}
    \left(-\frac{\hbar^2}{2m}\nabla^2+V(r)\right)\psi=E\psi.
\end{equation}
Born gave $\psi$ a physics meaning: The probability density for the particle that appear at position $x$.
\begin{problem}[The relation between image of $\psi$ and $E$]
    We know that, the second order derivative can represent the curvature. So with the energy growing, the image of the wave function will twist and cross the average line more and more.
    
\end{problem}



\section{Dirac's Notation}
\subsection{Bra \& Ket}
\quad
P. A. M Dirac divided the word ``bracket" into two parts, one is the bra, and the other is the ket. We call left vector as bra, and right vector as ket. We can denote\footnote{Clear and simple, its my favorite.} the state $\psi$ as $\ket{\psi}$, with its dual form $\bra{\psi}$. Each of these vectors contains a complete information about the state. We have to clarify the computation law about the bras and kets.
\begin{equation}
   a\ket{\alpha}+b\ket{\beta} \overset{DC.}{\longleftrightarrow}a^*\bra{\alpha}+b^*\bra{\beta}, \ \forall a,b\in \mathbb{C}.
\end{equation}
Inner product:
\begin{equation}
    \braket{\alpha}{\beta}:=\bra{\alpha} \ \ket{\beta}
\end{equation}
is a complex number.
Here we postulate two fundamental properties of inner products:
\begin{equation}\label{4.3}
    \braket{\alpha}{\beta}=\braket{\beta}{\alpha}^*
\end{equation}
and 
\begin{equation}
    \braket{\alpha}{\alpha}\ge 0.
\end{equation}
\quad 
The property of the second one is because we can take $\ket{\beta}=\ket{\alpha}$ in \eqref{4.3}, then we can obtain $\braket{\alpha}{\alpha}$ is a real number.


In fact, all the states forms a vector space $V$ over $\mathbb{C}$.



\subsection{Operator}\label{4.2}
All the operator\footnote{Some where will use hat to distinguish the operator, but not always for convenience.} forms a unitary ring $K$, it can be a $K$-module structure acting on $V$. If $X$ is an operator, then we define an operator (\textbf{Hermitian adjoint}) $X^\dagger$ as\footnote{When define the computing law of a Hermitian adjoint operator, we need to ensure any $\braket{\psi}{\phi}=\braket{\phi}{\psi}^*$. And if $T$ is an anti-linear operator, we DO NOT define $T^\dagger$. And we'd better understand a expression with right combination.} 
\begin{equation}
   X\ket{\psi} \overset{DC.}{\longleftrightarrow}\bra{\psi}X^\dagger.
\end{equation}
\singleline
\begin{notation}
Since $X\ket{\psi}$ is also a ket, we denote it as $\ket{X\psi}$. And its dual form is $\bra{X\psi}$.
\end{notation}
\singleline


%There's still something wrong.
%If $\bra{\psi}\ket{\psi}=1$, we can define inverse operator $X^{-1}$ satisfies:
%\begin{equation}
%    X^{-1}X=I.
%\end{equation}
%If  in addition, $X$ is unitary or anti-unitary, then
%\begin{equation}
%    \bra{\alpha}X^{-1}X\ket{\beta}=\braket{\alpha}{\beta}=\bra{X\alpha}\ket{X\beta}.
%\end{equation}
%Since $\ket{\alpha}$ and $\ket{\beta}$ are arbitrary,
%\begin{equation}
%    \bra{X\alpha}=\bra{\alpha}X^{-1}.
%\end{equation}

We say $X$ is \textbf{Hermitian} iff.
\begin{equation}
    X^\dagger=X.
\end{equation}
Easy to prove:
\begin{eqnarray}
    (XY)^\dagger&=&Y^\dagger X^\dagger,\\
    \left(\ket{\alpha}\bra{\beta}\right)^\dagger&=&\ket{\beta}\bra{\alpha},\\
\end{eqnarray}

We should tell difference between linear operator and anti-linear operator. They have important difference.
\newline
For linear operator $A$,
\begin{equation}
    A(\alpha\ket{\psi}+\beta\ket{\phi})=\alpha A\ket{\psi}+\beta A\ket{\phi}.
\end{equation}
\begin{equation}
    \bra{\beta}A\ket{\alpha}=\bra{\alpha}A^\dagger\ket{\beta}^*.
\end{equation}
But for anti-linear operator $T$,
\begin{equation}
    T(\alpha\ket{\psi}+\beta\ket{\phi})=\alpha^* T\ket{\psi}+\beta^* T\ket{\phi}.
\end{equation}
If we still want to define $T^\dagger$, we should satisfies the conditions in the footnote. Compare the form of the linear case, and let all the operator act on kets but not bras.
\begin{equation}\label{4.13}
   \bra{\beta}\ket{T\alpha}=\bra{\alpha}\ket{T^\dagger\beta}. 
\end{equation}
Then $\ket{\alpha}$ and $\ket{\beta}$ still anti-linear in this expression.
\singleline
\begin{theorem}
    \quad The eigenvalues of a Hermitian operator $A$ are real; the eigenkets
of $A$ corresponding to different eigenvalues are orthogonal.
\end{theorem}
\singleline
\begin{proof}
    We have 
    \begin{equation}
        A\ket{a_1}=a_1\ket{a_1},\  \bra{a_2}A=a_2^*\bra{a_2}.
    \end{equation}
Hence, 
\begin{equation}
    \left(a_1-a_2^*\right)\braket{a_2}{a_1}=0.
\end{equation}
Let $a_2=a_1$, then we obtain
\begin{equation}
    a_1=a_2^*.
\end{equation}
So $a_1$ is real. If $a_1\not=a_2$, then 
\begin{equation}
    \braket{a_2}{a_1}=0.
\end{equation}
i.e. the eigenkets are orthogonal.
\end{proof}
All the observables must be real, so its operator must be Hermitian.\footnote{We will explain it soon.}
\newline
If $\left\{\ket{a}\right\}$ is complete, then 
\begin{equation}\label{unit operator}
    \sum_{a}\ket{a}\bra{a}=1.
\end{equation}
Let it act on a state, then we can get the state represent as the bases of $\left\{\ket{a}\right\}$. And for a particular $a$, we can define the \textbf{projection operator} as 
\begin{equation}
    \Lambda_a=\ket{a}\bra{a}.
\end{equation}

If we use \eqref{unit operator} to act on both left and right of an operator $X$, then we can make it represent in the matrix form.

We write an observable $X$ as
\begin{equation}
    X=\sum_{a,b}\ket{a}\bra{a}X\ket{b}\bra{b}.
\end{equation}
Since $\bra{a}X\ket{b}$ is real, 
\begin{equation}
    X^\dagger=\sum_{a,b}\ket{b}\bra{b}X\ket{a}\bra{a}=X.
\end{equation}
So $X$ is Hermitian.

\section{Commutator and Anticommutator}
For any two operators $A$ and $B$, we define their \textbf{commutator} as
\begin{equation}
    \left[A,B\right]=AB-BA.
\end{equation}
And the \textbf{anticommutator} is
\begin{equation}
    \left\{A,B\right\}=AB+BA.
\end{equation}
Its easy to check
\begin{equation}
    [AB,C]=A[B,C]+[A,C]B,
\end{equation}
\begin{equation}\label{5.4}
    [A,BC]=[A,B]C+B[A,C],
\end{equation}
\begin{equation}
    [A,[B,C]]+[B,[A,C]]+[C,[A,B]]=0,
\end{equation}
\begin{equation}
    [A,B]^\dagger=[B^\dagger,A^\dagger].
\end{equation}
\begin{equation}
    \{AB,C\}=A\{B,C\}-[A,C]B,
\end{equation}
\begin{equation}
    \{A,BC\}=\{A,B\}C-B[A,C].
\end{equation}
Suppose $f(A),g(B)$ are differentiable functions of $A$ and $B$, let
\begin{equation}
    f(A)=\sum_{n=0}^{\infty}a_n A^n,
\end{equation}
we have 
\begin{equation}
    [A^n,B]=\sum_{k=0}^{n-1}A^{n-k-1}[A,B]A^k.
\end{equation}
If $[A,B]$ is commutable with $A$, then,
\begin{equation}
    [f(A),B]=f'(A)[A,B].
\end{equation}
Similarly, if $[A,B]$ is commutable with $B$, then,
\begin{equation}
    [A,g(B)]=g'(B)[A,B].
\end{equation}
\section{Compatible Observables}
Observables A and B are defined to be \textbf{compatible} when
the corresponding operators commute,
\begin{equation}
    [A,B]=0.
\end{equation}
\singleline
\begin{theorem}
    Suppose that $A$ and $B$ are compatible observables, and the eigen-values of $A$ are nondegenerate. Then the matrix elements 
 $\bra{a''}B\ket{a'}$ are all diagonal. 
\end{theorem}
\singleline

\section{Uncertainty Relation}
Define $\Delta A$ as 
\begin{equation}
    \Delta A:= A -\expval{A},
\end{equation}
where $\expval{A}$ is expectation value of $A$. And the \textbf{dispersion} of $A$ is
\begin{equation}
   \expval{ \left(\Delta A\right)^2}=\expval{\left(A^2-2A\expval{A}+\expval{A}^2\right)}=\expval{A^2}-\expval{A}^2.
\end{equation}
\singleline
\begin{theorem}
    For any state, we must have the following inequality:
    \begin{equation}\label{7.3}
        \expval{(\Delta A)^2}\expval{(\Delta B)^2}\ge\frac{1}{4}\left|\expval{[A,B]}\right|^2.
    \end{equation}
\end{theorem}
\singleline
\begin{proof}
    The Schwarz inequality\footnote{Consider $\ket{\alpha}+\lambda\ket{\beta}$ and take $\lambda=-\braket{\beta}{\alpha}\braket{\beta}{\beta}$.}:
    \begin{equation}
        \braket{\alpha}{\alpha}\braket{\beta}{\beta}\ge \left|\braket{\alpha}{\beta}\right|^2.
    \end{equation}
    Take\footnote{Blank ket $\ket{ }$ emphasizes the fact that our consideration may be applied
to any ket.} $$\ket{\alpha}=\Delta A\ket{ },\ \ket{\beta}=\Delta B \ket{ },$$
then, 
\begin{equation}
    \expval{\left(\Delta A\right)^2}\expval{\left(\Delta B\right)^2}\ge\left|\expval{\Delta A\Delta B}\right|^2.
\end{equation}
Here we use a trick: Any operator can be divided into Hermitian part and anti-Hermitian part, 
\begin{equation}
    \Delta A \Delta B=\frac{1}{2}[\Delta A, \Delta B ]+\frac{1}{2}\{\Delta A,\Delta B\}.
\end{equation}
Easy to prove that the expect value of Hermitian operator is real, and the anti-Hermitian's is purely imaginary. Thus,
\begin{equation}
    \left|\expval{\Delta A\Delta B}\right|^2=\frac{1}{4}\left|\expval{[\Delta A,\Delta B]}\right|^2+\frac{1}{4}\left|\expval{\{\Delta A,\Delta B\}}\right|^2.
\end{equation}
One have $[\Delta A,\Delta B]=[A,B]$ and $\left|\dots\right|^2\ge 0$, then we get the result.
\end{proof}

\section{Position and Momentum}
\quad I will follow J. J. Sakurai's steps to derive some famous results. As continuous spectra, they have following changes \footnote{We use $\xi $ to represent a continuous variable.}:
\begin{equation}
    \braket{a'}{a''}=\delta_{a',a''}\longrightarrow \braket{\xi'}{\xi''}=\delta\left(\xi'-\xi''\right).
\end{equation}
Where $\delta\left(\xi'-\xi''\right)$ is the \href{run:Dirac delta function.pdf alias}{Dirac delta function}.
\begin{equation}
    \sum_{a}\ket{a}\bra{a}=1\longrightarrow \int \dd{\xi} \ket{\xi}\bra{\xi}=1.
\end{equation}
\subsection{Position \& Wave Function}
For position, we can measure its position, which means we can get its components at the same time, they are compatible. So 
\begin{equation}
    [\hat{x}_i,\hat{x}_j]=0.
\end{equation}
\begin{equation}
    \ket{\mathbf{x}}=\ket{x,y,z}.
\end{equation}
\begin{equation}
    \hat{x}\ket{\mathbf{x}}=x\ket{\mathbf{x}},\ \hat{y}\ket{\mathbf{x}}=y\ket{\mathbf{x}},\ \hat{z}\ket{\mathbf{x}}=z\ket{\mathbf{x}}.
\end{equation}
We call 
\begin{equation}
    \psi_{\alpha}(x)=\braket{x}{\alpha}
\end{equation}
the wave function.
\subsection{Translation}
Consider an operator $\mathscr{J}(\dd{\mathbf{x}})$ satisfying
\begin{equation}
    \mathscr{J}(\dd{\mathbf{x}})\ket{\mathbf{x}}=\ket{\mathbf{x}}.
\end{equation}
Then 
\begin{equation}
    \mathscr{J}^\dagger(\dd{\mathbf{x}})\mathscr{J}(\dd{\mathbf{x}})=1
\end{equation}
needs to be guaranteed. We expect the translation does not depend on the trace, which means
\begin{equation}
    \mathscr{J}(\dd{\mathbf{x}}_1+\dd{\mathbf{x}}_2)=\mathscr{J}(\dd{\mathbf{x}}_1)+\mathscr{J}(\dd{\mathbf{x}}_2).
\end{equation}
For the third property,suppose we consider a translation in the opposite direction;
we expect the opposite-direction translation to be the same as the inverse of the
original translation:
\begin{equation}
    \mathscr{J}(-\dd{\mathbf{x}})=\mathscr{J}^{-1}(\dd{\mathbf{x}}).
\end{equation}
For the fourth property,
\begin{equation}
    \lim_{\dd{\mathbf{x}}\rightarrow0}\mathscr{J}(\dd{\mathbf{x}})=1.
\end{equation}
Consider
\begin{equation}\label{8.11}
    \mathscr{J}(\dd{\mathbf{x}})=1-\ii\hat{\mathbf{K}}\cdot\dd{\mathbf{x}},
\end{equation}
it let all the properties we want hold, if $\hat{\mathbf{K}}$ is Hermitian. We can check that 
\begin{equation}
    [\hat{\mathbf{x}},\mathscr{J}(\dd{\mathbf{x}})]=\dd{\mathbf{x}}.
\end{equation}
Plug in \eqref{8.11}, we obtain
\begin{equation}\label{8.13}
    [\hat{x}_i,\hat{K}_j]=\ii\delta_{ij}.
\end{equation}

\subsection{Momentum}
An infinitesimal translation in classical mechanics can be regarded as a canonical transformation,
\begin{equation}
    \mathbf{x}_{\text{new}}=\mathbf{x}+\dd{\mathbf{x}},\ \mathbf{p}_{\text{new}}=\mathbf{p}.
\end{equation}
obtainable from the generating function
\begin{equation}
    F(\mathbf{x},\mathbf{p})=\mathbf{x}\cdot\mathbf{p}_{\text{new}}+\mathbf{p}\cdot\dd{\mathbf{x}}.
\end{equation}
This equation has a striking similarity to the infinitesimal translation operator. Let 
\begin{equation}\label{8.16}
    \mathscr{J}(\dd{\mathbf{x}})=1-\ii\hat{\mathbf{p}}\cdot\dd{\mathbf{x}}/\hbar. 
\end{equation}
The commutation relation \eqref{8.13} now becomes
\begin{equation}
    [\hat{x}_i,\hat{p}_j]=\ii\hbar\delta_{i,j}.
\end{equation}
By \eqref{7.3}, we obtain the \textbf{position-momentum uncertainty relation}:
\begin{equation}
    \expval{\left(\Delta x\right)^2}\expval{\left(\Delta p\right)^2}\ge\frac{\hbar^2}{4}
\end{equation}
As for finite position\label{displacement operator}, 
\begin{equation}
    \mathscr{J}(\Delta \mathbf{x})=\lim_{N\rightarrow \infty}\left(1-\frac{\ii\hat{\mathbf{p}}\cdot\Delta\mathbf{x}}{N\hbar}\right)^N=\exp\left(-\frac{\ii\hat{\mathbf{p}}\cdot\Delta \mathbf{x}}{\hbar}\right).
\end{equation}
By computation,
\begin{equation}
    [\hat{p}_i,\hat{p}_j]=0.
\end{equation}
\subsection{Momentum Operator in the Position Basis}
By computing $\mathscr{J}\left(\dd{\mathbf{x}}\right)\ket{\alpha}$ in
the representation where the position eigenkets are used as base kets, and plug in \eqref{8.16}, we obtain 
\begin{equation}
    \hat{\mathbf{p}}\ket{\alpha}=\int \dd{\mathbf{x}}\ket{\mathbf{x}}\left(-\ii\hbar\nabla\bra{\mathbf{x}}\ket{\alpha}\right).
\end{equation}
That is also 
\begin{equation}\label{8.23}
    \bra{\mathbf{x}}\hat{\mathbf{p}}\ket{\alpha}=-\ii\hbar\nabla\braket{\mathbf{x}}{\alpha}.
\end{equation}
\subsection{Momentum-Space Wave Function}
The notation $\phi_\alpha(p)$ is often used 
\begin{equation}
    \braket{p}{\alpha}=\phi_{\alpha}(p).
\end{equation}
To transform the bases from position to momentum, we need to calculate $\braket{x}{p}$.
\newline
One have 
\begin{equation}
    \bra{x}\hat{p}\ket{p}=p\bra{x}\ket{p}.
\end{equation}
By \eqref{8.23},
\begin{equation}
   \bra{x}\hat{p}\ket{p}=-\ii\hbar\frac{\pa}{\pa x}\bra{x}\ket{p}.
\end{equation}
Thus, 
\begin{equation}
    \bra{x}\ket{p}=A\exp\left(\frac{\ii px}{\hbar}\right).
\end{equation}
Do the derivation will lose a constant, but integration won't.\footnote{Is it an easy integration?}
\begin{equation}
    \delta\left(x-x'\right)=\int \dd{p}\bra{x}\ket{p}\bra{p}\ket{x'}=2\pi \hbar AA^*\delta(x-x').
\end{equation}
For convenience, we take $A$ as a real number, then 
\begin{equation}
    \bra{x}\ket{p}=\frac{1}{\sqrt{2\pi \hbar}}\exp\left(\frac{\ii px}{\hbar}\right).
\end{equation}
For three dimension case, 
\begin{equation}
    \bra{\mathbf{x}}\ket{\mathbf{p}}=\left[\frac{1}{\left(2\pi\hbar\right)^{\frac{3}{2}}}\right]\exp\left(\frac{\ii\mathbf{p}\cdot\mathbf{x}}{\hbar}\right).
\end{equation}
\subsection{Dirac's Corresponding Rule}
Replace classical Poission bracket by commutator as follows\footnote{I think the $i\hbar$ comes from the translation where setting a constant as $i\hbar$.}
\begin{equation}
    [\quad ,\quad ]_{\text{classical}}\longrightarrow \frac{[\quad ,\quad ]}{\ii\hbar}.
\end{equation}




\section{Schrödinger Equation}
Let $\mathscr{U}$ be the time-evolution operator, which means
\begin{equation}
    \ket{\psi(t)}=\mathscr{U}(t,t_0)\ket{\psi(t_0)}.
\end{equation}
We want it to satisfy the following conditions:
\newline
(1) $\mathscr{U}$ should be linear:
\begin{equation}
    \mathscr{U}(t,t_0)\left[c_1\ket{\psi_1(t_0)}+c_2\ket{\psi_2(t_0)}\right]=c_1\mathscr{U}(t,t_0)\ket{\psi_1(t_0)}+c_2\mathscr{U}(t,t_0)\ket{\psi_2(t_0)}.
\end{equation}
(2) $\mathscr{U}$ should be unitary (to make a state always normalized):
\begin{equation}
    \mathscr{U}^\dagger\mathscr{U}=\mathscr{U}\mathscr{U}^\dagger=1.
\end{equation}
(3) Composition property:
\begin{equation}
    \mathscr{U}(t_2,t_1)\mathscr{U}(t_1,t_0)=\mathscr{U}(t_2,t_0).
\end{equation}
(4) Continuous and identity:
\begin{equation}
    \lim_{\dd{t}\rightarrow0}\mathscr{U}(t_0+\dd{t},t_0)=1.
\end{equation}
Similar to the previous section, we can use a Hermitian operator to construct this operator. And by the classical corresponding rule, we have 
\begin{equation}
    \mathscr{U}(t_0+\dd{t},t_0)=1-\frac{\ii H \dd{t}}{\hbar}.
\end{equation}
Then,
\begin{equation}
    \mathscr{U}(t+\dd{t},t_0)=\mathscr{U}(t+\dd{t},t)\mathscr{U}(t,t_0)=\left(1-\frac{\ii H \dd{t}}{\hbar}\right)\mathscr{U}(t,t_0).
\end{equation}
That is 
\begin{equation}
    \ii \hbar \frac{\pa}{\pa t}\mathscr{U}(t,t_0)=H\mathscr{U}(t,t_0).
\end{equation}
This is the \textbf{Schrödinger equation for the time-evolution operator}. Apply this operator to a state $\ket{\alpha,t_0;t}$, we obtain
\begin{equation}
    \ii \hbar \frac{\pa}{\pa t}\ket{\alpha,t_0;t}=H\ket{\alpha,t_0;t}.
\end{equation}
In integration form,
\begin{equation}
    \mathscr{U}(t,t_0)=1-\frac{\ii}{\hbar}\int_{t_0}^{t}\dd{t_1}H(t_1)\mathscr{U}(t_1,t_0).
\end{equation}
Then we can induction on $n$ that 
\begin{equation}
    \mathscr{U}(t,t_0)=\sum_{n=0}^{\infty}\left(\frac{-\ii}{\hbar}\right)^{n}\int_{t_0}^{t}\dd{t_1}\int_{t_0}^{t_1}\dd{t_2}\dots\int_{t_0}^{t_{n-1}}\dd{t_n}H(t_1)H(t_2)\ldots H(t_n).
\end{equation}

Now we want to simplify this expression. The bad thing is $H$ at different time may not commute. So we define a time-ordering operator $\mathcal{T}$:
\begin{equation}
    \mathcal{T}[A(t_1)B(t_2)]=\begin{cases}
        B(t_2)A(t_1),&\text{if }t_1<t_2\\
        A(t_1)B(t_2),&\text{if }t_1\ge t_2\\
    \end{cases}.
\end{equation}
If we consider the integration is dealing on $[t_0,t]^n$, then it can be divided into $n!$ part, each part has an order of a permutation of $(t_1,\ldots,t_n)$, but it should in order of $(t_1,\ldots,t_n)$. Thus,
\begin{equation}
    \begin{aligned}
    &\int_{t_0}^{t}\dd{t_1}\int_{t_0}^{t_1}\dd{t_2}\dots\int_{t_0}^{t_{n-1}}\dd{t_n}H(t_1)H(t_2)\ldots H(t_n)\\
    =&\frac{1}{n!}\int_{t_0}^{t}\dd{t_1}\int_{t_0}^{t}\dd{t}\dots\int_{t_0}^{t}\dd{t_n}\mathcal{T}\left[H(t_1)H(t_2)\ldots H(t_n)\right]\\
    &=\frac{1}{n!}\mathcal{T}\left[\left(\int_{t_0}^{t}\dd{t'}H(t')\right)^n\right].
    \end{aligned}
\end{equation}
Therefore,
\begin{equation}\label{9.14}
    \mathscr{U}(t,t_0)=\mathcal{T}\exp\left[-\frac{\ii}{\hbar}\int_{t_0}^{t}\dd{t'}H(t')\right].
\end{equation}
In particular, if $H(t)$ is commutable at any different time, then 
\begin{equation}
    \mathscr{U}(t,t_0)=\exp\left[-\frac{\ii}{\hbar}\int_{t_0}^{t}\dd{t'}H(t')\right].
\end{equation}
Moreover, if $H$ is time-independent, then
\begin{equation}
    \mathscr{U}(t,t_0)=\exp\left[-\frac{\ii}{\hbar}H(t-t_0)\right].
\end{equation}

\section{Probability Density and Probability Current}
Let $\psi $ be  the wave function, then the probability density is
\begin{equation}
    \rho:=\psi\psi^*.
\end{equation}
The probability need to be conserved,
\begin{equation}
    \frac{\pa \rho}{\pa t}+\nabla \cdot\mathbf{j}=0.
\end{equation}
Then we can deduce from Schrödinger equation that 
\begin{equation}
    \mathbf{j}=\left(\frac{\hbar}{m}\right)\mathrm{Im}(\psi^*\nabla\psi).
\end{equation}
If we write $\psi$ into the form of 
\begin{equation}
    \psi=\sqrt{\rho}\ee^{\frac{\ii S}{\hbar}},
\end{equation}
then\footnote{\hyperref[charged case]{Here} is the case with charge.} 
\begin{equation}
    \mathbf{j}=\frac{\rho\nabla S}{m}.
\end{equation}
Taking the classical limit, we can see that $S$ is the action.
\begin{equation}
    \int\mathbf{j}\dd{\mathbf{x}}=\frac{\expval{\mathbf{p}}}{m}.
\end{equation}
It is some thing like velocity.


\section{Exponential Operators and Baker-Hausdorff Lemma }
If it exists, then we denote\footnote{Sometimes we denote as $\exp(A)$.}
\begin{equation}
    \ee^A=\sum_{n=0}^{\infty}\frac{A^n}{n!}.
\end{equation}
Easy to check that if $[A,B]=0$, then 
\begin{equation}
    \exp(A)\exp(B)=\exp(A+B).
\end{equation}
Define\footnote{We write extra $\ii$ because we often use the Hermitian conjugate, and $i$ will give a negative sign to fit the form if $G$ is Hermitian.}
\begin{equation}
    O(\lambda)=\ee^{\ii\lambda G}A\ee^{-\ii\lambda G},
\end{equation}
where $A$ and $G$ are operators, and $\lambda$ is a complex parameter. Then,
\begin{equation}
    \frac{\dd}{\dd{\lambda}}O(\lambda)=\ii \ee^{\ii\lambda G}[G,A]\ee^{-\ii\lambda G}=\ii[G,O(\lambda)].
\end{equation}
Hence, 
\begin{equation}
    O(\lambda)=O(0)+\ii\int_{0}^{\lambda}\dd{\lambda_1}[G,O(\lambda_1)].
\end{equation}
We have $O(0)=A$. And we replace $O(\lambda_1)$ similarly, also for $\lambda_2,\lambda_3,\dots$, then we obtain,
\begin{equation}
    O(\lambda)=A+\ii\int_{0}^{\lambda}\dd{\lambda_1}[G,A]+\ii^2\int_{0}^{\lambda}\dd{\lambda_1}\int_{0}^{\lambda_1}\dd{\lambda_2}[G,[G,A]]+\dots
\end{equation}
Easy to check 
\begin{equation}
    \int_{0}^{\lambda}\dd{\lambda_1}\int_{0}^{\lambda_1}\dd{\lambda_2}\dots\int_{0}^{\lambda_{n-1}}\dd{\lambda_n}=\frac{\lambda^n}{n!}.
\end{equation}
Therefore\footnote{ It is easy to take the wrong signature, remember it is something like derivative and note the first term, like $[G,A]$, then it won't be wrong.},
\begin{equation}
    \boxed{\ee^{\ii\lambda G}A\ee^{-\ii\lambda G}=\sum_{n=0}^{\infty}\frac{\left(\ii\lambda\right)^n}{n!}C_G^{(n)}(A)},
\end{equation}
where\footnote{This notation is not formal, but the following notation ``$\mathrm{Ad}$'' (get from Deepseek)  may be better to use in articles.}, 
\begin{equation}
    C_G(A)=[G,A],\ C_G^{(n)}(A)=[G,C_G^{(n-1)}(A)].
\end{equation}
Or we can write in the form\label{Baker-Hausdorff lemma} 
\begin{equation}
    \ee^\Omega A \ee^{-\Omega }=\ee^{\mathrm{Ad}_\Omega}(A).
\end{equation}

Let us consider a special case: $[A,B]$ is  commutable with $A$ and $B$. By Baker-Hausdorff lemma, we have
\begin{equation}
    \ee^A\ee^B\ee^{-A}=\ee^B+[A,\ee^B]+\dots.
\end{equation}
By \eqref{5.4}, we can induct on $n$ that 
\begin{equation}
    [A,[A,B]^{n-1}\ee^B]=[A,B]^n\ee^B.
\end{equation}
So, 
\begin{equation}\label{9.13}
    \ee^A\ee^B=\ee^B\ee^A\ee^{[A,B]}.
\end{equation}


We also have another more symmetrical form\footnote{In fact we do not need any condition, then we can derive a general form, but that is a bit complex and unnecessary.}:

\singleline

\begin{theorem}

    \begin{equation}
         [A,[A,B]]=[B,[A,B]]=0\Rightarrow \ee^A \ee^B = \ee^{A + B} \ee^{\frac{1}{2}[A, B]}.
    \end{equation}
\end{theorem}
\singleline
\begin{proof}
    Let 
    \begin{equation}
        O(\lambda)=\ee^{\lambda A}\ee^{\lambda B},
    \end{equation}
    then,
    \begin{equation}
        \frac{\dd{O}}{\dd{\lambda}}=\ee^{\lambda A}\left(A+B\right)\ee^{\lambda B}.
    \end{equation}
    We want to get a differential equation of $O(\lambda)$, so we have to take $(A+B)$ to the left of $\exp(\lambda A)$\footnote{Trick: If there is not we want, then create one, like $+1\, -1$, here we times $1$.}.
    \begin{equation}
        \ee^{\lambda A}B\ee^{\lambda B}=\ee^{\lambda A}B\ee^{-\lambda A}\ee^{\lambda A}\ee^{\lambda B}.
    \end{equation}
    By Baker-Hausdorff lemma, we obtain
    \begin{equation}
        \frac{\dd{O}}{\dd{\lambda}}=\left[\left(A+B\right)+\lambda[A,B]\right]O.
    \end{equation}
    The solution is 
    \begin{equation}
        O=\exp\left[\lambda(A+B)+\frac{1}{2}\lambda^2[A,B]\right].
    \end{equation}
\end{proof}
\singleline



\section{Harmonic Oscillator}

We discuss the 1D case first. We have the Hamiltonian
\begin{equation}
    \hat{H}=\frac{\hat{p}^2}{2m}+\frac{1}{2}m\omega^2\hat{x}^2.
\end{equation}
\subsection{Method of Analysis (Hermite polynomials)}
We solve the wave function in position representation, then we obtain many information. Let $z=\frac{x}{\sqrt{\frac{\hbar}{m\omega}}}$, then 
\begin{equation}
    \left[-\frac{1}{2}\frac{\dd^2}{\dd{z}^2}+\frac{1}{2}z^2\right]\psi(z)=\frac{E}{\hbar \omega}\psi(z).
\end{equation}
A must to satisfy is 
\begin{equation}
    \lim_{z\rightarrow \infty}\psi(z)=0.   
\end{equation}
So we first analyze the behavior of $\psi(z)$ at $z\rightarrow \pm\infty$. For $\psi''=z^2\psi$, we try the solution\footnote{This may keep the form.} $\psi(z)=e^S(z)$
\begin{equation}
    \psi'=S'\psi,\ \psi''=\left(S''+S'^2\right)\psi.
\end{equation}
Comparison of two expression yields
\begin{equation}
    S''+S'^2=z^2.
\end{equation}
The leading order leads to $s'=\pm z$, $s=\pm\frac{1}{2}z^2$. So we can try the solution 
\begin{equation}
    \psi(z)=\ee^{-\frac{z^2}{2}} u(z).
\end{equation}
\begin{equation}\label{9.6}
    \frac{\dd^2}{\dd{z}^2}u(z)-2z\frac{\dd}{\dd{z}}u(z)-\left(\lambda-1\right)u(z)=0.
\end{equation}
We consider the series solution, let
\begin{equation}
    u(z)=\sum_{k=0}^{+\infty}a_kz^k.
\end{equation}
The we can deduce that 
\begin{equation}
    \frac{a_{k+2}}{a_k}=\frac{2k+1-\lambda}{(k+1)(k+2)}.
\end{equation}
We have $u(\pm\infty)=1$, so there must exists an $N\in \mathbb{N}$, for any $k>N$, 
\begin{equation}
    a_{k}=0.
\end{equation}
Therefore, 
\begin{equation}
    \lambda_n=2n+1,\ n=0,1,2,\dots
\end{equation}
which means 
\begin{equation}
    E_n=\left(n+\frac{1}{2}\right)\hbar \omega.
\end{equation}
The solution of \eqref{9.6} is Hermite polynomials\footnote{There's some properties about \href{run:Hermite polynomial.pdf alias}{Hermite polynomial}.} $H_n(z)$.
\begin{equation}
    \psi(x)=\ee^{-\frac{1}{2}\frac{m\omega x^2}{\hbar}}\sum_{n=0}^{+\infty}\frac{c_n}{n!}H_n\left(x\slash\sqrt{\frac{\hbar}{m\omega}}\right).
\end{equation}
And for a fixed $n$, the normalized wavefunction is
\begin{equation}    
    \psi_n(z)=\frac{1}{\sqrt{2^nn!\sqrt{\pi}}}\ee^{-\frac{z^2}{2}}H_n(z).
\end{equation}


\subsection{Method of Algebra}
In usual computing law, 
\begin{equation}
    H=\frac{p^2}{2m}+\frac{1}{2}m\omega^2x^2=\frac{1}{2}m\omega^2\left(x-\frac{\ii p}{m\omega}\right)\left(x+\frac{\ii p}{m\omega}\right).
\end{equation}
Let \footnote{If we denote $l=\sqrt{\frac{\hbar}{m\omega}}$, then it will be $a=\frac{1}{\sqrt{2}}\left(\frac{x}{l}+\ii\frac{pl}{\hbar}\right)$. $\frac{1}{\sqrt{2}}$ seems like to normalize.}
\begin{equation}
    \hat{a}^\dagger=\sqrt{\frac{m\omega}{2\hbar}}\left(\hat{x}-\frac{\ii\hat{p}}{m\omega}\right),\ \hat{a}=\sqrt{\frac{m\omega}{2\hbar}}\left(\hat{x}+\frac{\ii\hat{p}}{m\omega}\right).
\end{equation}
Then, 
\begin{equation}
    [\hat{a},\hat{a}^\dagger]=1.
\end{equation}
Let 
\begin{equation}
    \hat{N}=\hat{a}^\dagger\hat{a},
\end{equation}
then,
\begin{equation}
    \hat{H}=\hbar\omega \left(\hat{N}+\frac{1}{2}\right).
\end{equation}
So $\hat{N}$ is compatible with $\hat{H}$. We denote an energy eigenket of $\hat{N}$ by its eigenvalue\footnote{We will later show that n must be a nonnegative integer.} $n$, so
\begin{equation}
    \hat{N}\ket{n}=n\ket{n},
\end{equation}
\begin{equation}
    \hat{H}\ket{n}=\left(n+\frac{1}{2}\right)\hbar\omega\ket{n}.
\end{equation}

To appreciate the physical significance of $\hat{a},\hat{a}^\dagger$, and $\hat{N}$, let us first note that 
\begin{equation}
    [\hat{N},\hat{a}]=-\hat{a},\ [\hat{N},\hat{a}^\dagger]=\hat{a}^\dagger.
\end{equation}
As a result, we have
\begin{equation}
    \hat{N}\hat{a}^\dagger\ket{n}=[\hat{N},\hat{a}^\dagger]\ket{n}+\hat{a}^\dagger\hat{N}\ket{n}=\left(n+1\right)\hat{a}^\dagger\ket{n},
\end{equation}
\begin{equation}
    \hat{N}\hat{a}\ket{n}=[\hat{N},\hat{a}]\ket{n}+\hat{a}\hat{N}\ket{n}=\left(n-1\right)\hat{a}\ket{n}.
\end{equation}
We write
\begin{equation}
    \hat{a}\ket{n}=c\ket{n-1},
\end{equation}
then, 
\begin{equation}\label{9.24}
    \bra{n}\hat{N}\ket{n}=\bra{n}\hat{a}^\dagger\hat{a}\ket{n}=\left|c\right|^2.
\end{equation}
Thus, 
\begin{equation}
    \hat{a}\ket{n}=\sqrt{n}\ket{n-1}.
\end{equation}
Similarly, it is easy to show that\footnote{Memory trick: the square root of a lager one.}
\begin{equation}
    \hat{a}^\dagger\ket{n}=\sqrt{n+1}\ket{n+1}.
\end{equation}
From \eqref{9.24} we know that $n\ge0.$
If we act $\hat{a}$ on a state for many times, we can conclude that the sequence must
terminate with $n=0$, or it won't stop and $n$ will become not real.
Use 
\begin{equation}
    \hat{x}=\sqrt{\frac{\hbar}{2m\omega}}\left(\hat{a}+\hat{a}^\dagger\right),\ \hat{p}=\ii\sqrt{\frac{m\hbar\omega}{2}}\left(-\hat{a}+\hat{a}^\dagger\right),
\end{equation}
we can get more information. To solve the wave function, we can deduce $\bra{x}\hat{a}\ket{0}=0$, which leads to a differential equation for the wave function.


\subsection{Further Discussion of 1D Case: Coherent State}
\begin{quotation}
    We have seen that an energy eigenstate does not behave like the classical
oscillator—in the sense of oscillating expectation values for $x$ and $p$—no matter
how large $n$ may be. We may logically ask, How can we construct a superposition
of energy eigenstates that most closely imitates the classical oscillator? In wave-function language, we want a wave packet that bounces back and forth without
spreading in shape. It turns out that a coherent state defined by the eigenvalue
equation for the non-Hermitian annihilation operator $a$,
$$a\ket{\lambda}=\lambda\ket{\lambda},$$
with, in general, a complex eigenvalue $\lambda$ does the desired job. 
\begin{flushright}
    {\raggedleft \textit{---Modern Quantum Mechanics}}
\end{flushright}
\end{quotation}
We want it to be related to the states we have known. And the simplest one is $\ket{0}$. Let $\ket{\lambda}=A\ket{0}$. Then what we expect is $aA\ket{0}=\lambda A\ket{0}$. Or in another form:
\begin{equation*}
    (A^{-1}aA-\lambda)\ket{0}=f(a)\ket{0},
\end{equation*}
where $f$ is a arbitrary function. We want to make it easy, let us set $f(a)=a$. Then by the \hyperref[Baker-Hausdorff lemma]{Baker-Hausdorff lemma}, the following let what we want holds
\begin{equation}
    A=\ee^{\lambda a^\dagger}.
\end{equation}
use \eqref{9.13} to do the normalization\footnote{Expand the series we get $\exp(\lambda a)\ket{0}=\ket{0}$.},
\begin{equation}
    \expval{e^{\lambda^* a}e^{\lambda a^\dagger}}{0}=e^{\left|\lambda\right|^2}.
\end{equation}
Therefore\footnote{A Poission distribution.},
\begin{equation}
    \ket{\lambda}=\ee^{-\left|\lambda\right|^2/2}\ee^{\lambda a^\dagger}\ket{0}=\ee^{-\left|\lambda\right|^2/2}\sum_{n=0}^{\infty}\frac{\lambda^n}{\sqrt{n!}}\ket{n}.
\end{equation}
We have discussed in \ref{displacement operator} that the operator $e^{-i  pl/\hbar}$ is a displacement operator. Let us show we can obtain a coherent state by applying it on $\ket{0}$.
\begin{equation}
    \ee^{-ip\Delta x/\hbar}\ket{0}=\ee^{\frac{(a^\dagger-a)\Delta x}{\sqrt{2}l}}\ket{0}\sim \ee^{\frac{a^\dagger \Delta x}{\sqrt{2}l}}\ket{0}.
\end{equation}
\subsection{High Dimensional Case}
We use the Einstein summation convention. Hamilton in $n$-dimensional case can be written as
\begin{equation}
    H=\frac{p^ip_i}{2m}+\frac{1}{2}m\omega^2x^ix_i.
\end{equation}
And the creation and annihilation operators are
\begin{equation}
    a_i=\frac{1}{\sqrt{2}}\left(\frac{x_i}{l}+\frac{\ii p_il}{\hbar}\right), \quad a^\dagger_i=\frac{1}{\sqrt{2}}\left(\frac{x_i}{l}-\frac{\ii p_il}{\hbar}\right).
\end{equation}
\begin{equation}
    [a_i,a_j]=0,\quad [a_i,a^\dagger_j]=\delta_{ij}.
\end{equation}
If we denote $a^ia_i^\dagger$ as $N$, then we can written $H$ as 
\begin{equation}
    H=\hbar \omega (N+\frac{n}{2}).
\end{equation}
Or $H^i_i$ \footnote{It's my own notation means $\displaystyle \sum_i H_i.$}if we denote $H_i=\hbar \omega (a_i^\dagger a_i+\frac{1}{2})$.

It's easy to check that 
\begin{equation}
    [a_i^\dagger a_j,H]=0.
\end{equation}
That means the angular momentum is conserved.


\section{Gauge Transformations in Electromagnetism}
\subsection{Gauge Transformations}
\label{charged case}In Classic mechanics, the Hamiltonian is
\begin{equation}
    H=\frac{1}{2m}\left(\mathbf{p}-\frac{q\mathbf{A}}{c}\right)^2+q\phi.
\end{equation}
Where $\mathbf{p}$ is the canonical momentum, $\mathbf{A}$ is the vector potential, $q$ is the charge and $\phi$ is the scalar potential. And now the canonical momentum $\mathbf{p}$ is the e generator of translation. And kinematical (or mechanical) momentum, denoted by:
\begin{equation}\label{12.2}
    \mathbf{\Pi}:=\mathbf{p}-\frac{q\mathbf{A}}{c}.
\end{equation}
Easy to check that
\begin{equation}
    [\Pi_i,\Pi_j]=\frac{\ii\hbar q}{c}\varepsilon_{ijk}B_k.
\end{equation}
The Hamiltonian:
\begin{equation}
    H=\frac{\Pi^2}{2m}+q\phi.
\end{equation}
From \eqref{12.2} we can use the substitution 
\begin{equation}
    \mathbf{p}\longrightarrow \mathbf{p}-\frac{q\mathbf{A}}{c}
\end{equation}

In position representation\footnote{We can use it only when the $\nabla$ comes from $\mathbf{p}$.},
\begin{equation}
    \nabla\longrightarrow \nabla-\left(\frac{\ii q}{\hbar c}\right)\mathbf{A}.
\end{equation}
to get the expressions of the electromagnetism case. For example, the probability current now is 
\begin{equation}\label{12.8}
    \mathbf{j}=\frac{\rho}{m}\left(\nabla S-\frac{q\mathbf{A}}{c}\right).
\end{equation}
\begin{equation}
    \int \mathbf{j}\dd{\mathbf{x}}=\frac{\expval{\mathbf{\Pi}}}{m}.
\end{equation}
$\mathbf{E}$ and $\mathbf{B}$ are unchanged under
\begin{equation}
    \phi\rightarrow \phi-\frac{1}{c}\frac{\pa \Lambda}{\pa t},\quad \mathbf{A}\rightarrow\mathbf{A}+\nabla \Lambda.
\end{equation}
We consider the time-independent operator, so in the remaining part of this section, the term \textit{gauge transformation} refers to the case $\frac{\pa \Lambda}{\pa t}=0$.

Let $\ket{\alpha},\ket{\tilde{\alpha}}$ be the state ket in the presence of $\mathbf{A}$ and $\tilde{\mathbf{A}}$, where,
\begin{equation}
    \tilde{\mathbf{A}}=\mathbf{A}+\nabla \Lambda.
\end{equation}
They must have the same physical situation, at least we need to make sure
\begin{equation}
   \braket{\alpha}=\braket{\tilde{\alpha}} ,\quad \expval{\mathbf{x}}{\alpha}=\expval{\mathbf{x}}{\tilde{\alpha}},\quad \expval{\mathbf{\Pi}}{\alpha}=\expval{\tilde{\mathbf{\Pi}}}{\tilde{\alpha}}.
\end{equation}
Construct an operator $g$ that relates $\ket{\tilde{\alpha}}$ to $\ket{\alpha}$.
\begin{equation}
    \ket{\tilde{\alpha}}=g\ket{\alpha}.
\end{equation}
By intuition, $g$ is a function of $\Lambda$, and it is a function of $\mathbf{x}$, so it is commutable with $\mathbf{x}$, $g^\dagger\mathbf{x} g=\mathbf{x}$. The first and the third conditions give restrictions:
\begin{equation}
    g^\dagger g=1.
\end{equation}
    \begin{equation}\label{12.14}
    g^\dagger \mathbf{p}g=\mathbf{p}+\frac{q\nabla\Lambda}{c}.
\end{equation}
It is easy to find 
\begin{equation}
    g=\exp\left(\frac{\ii q\Lambda}{\hbar c}\right)
\end{equation}
satisfies the above conditions. And we have 
\begin{equation}
    g^\dagger \tilde{\mathbf{\Pi}}^ng=\prod_{k=1}^{n}g^\dagger \tilde{\mathbf{\Pi}}g=\mathbf{\Pi}^n.
\end{equation}
So, for any function $f$,
\begin{equation}\label{12.17}
    g^\dagger f\left(\tilde{\mathbf{\Pi}}\right) g=f\left(\mathbf{\Pi}\right).
\end{equation}

\eqref{12.14} and \eqref{12.17} tell us, mechanical momentum is gauge invariant, but the canonical momentum is not.

Form the wave function, 
\begin{equation}
    S\longrightarrow S+\frac{q\Lambda}{c}.
\end{equation}
This is highly satisfactory because we see that the probability flux given by \eqref{12.8} is then gauge invariant. 

\textbf{DO NOT FORGET} that when using the gauge transformation, not only the states but also the operators will change. Let's check the Schrödinger equation is still hold under gauge transformation.
\begin{equation}
 \tilde{H} \ket{\tilde{\alpha}}=g g^\dagger \tilde{H}g\ket{\alpha}=g H\ket{\alpha}=\ii\hbar  \frac{\pa}{\pa t}g \ket{\alpha}=\ii\hbar \frac{\pa }{\pa t}\ket{\tilde{\alpha}}.
\end{equation}

Since $t$ is only a parameter, it does not affect the commutators, so when $\frac{\pa\Lambda}{\pa t}\not=0$, \eqref{12.17} still holds. \textbf{BUT}, $\tilde{H}\not=g^\dagger Hg$, since  $\phi$ contributes a term. So our notation is not convenient in the $\Lambda$ is time-dependent case.

\subsection{Landau Levels and Quantum Hall Effect}
We use IS of units this subsection.
\subsubsection{Landau Gauge}
Let's consider a simple magnetic field,
\begin{equation}
    \mathbf{B}=-B\hat{\mathbf{z}}.
\end{equation}
We take 
\begin{equation}
    A_x=By,\quad A_y=A_z=0.
\end{equation}
We just consider 2D case, the Hamiltonian is 
\begin{equation}
    H=\frac{\left(p_x-qBy\right)^2}{2m}+\frac{p_y^2}{2m}=\frac{1}{2}m\omega_c^2\left(y-\frac{p_xl_B^2}{\hbar}\right)^2+\frac{p_y^2}{2m},
\end{equation}
where,
\begin{equation}
    \omega_c=\frac{qB}{m},\quad l_B=\sqrt{\frac{\hbar}{qB}}.
\end{equation}
Since $\frac{\pa H}{\pa x}=0$, we suppose 
\begin{equation}
    \psi_{n,k_x}(x,y)=\mathrm{e}^{\mathrm{i}k_x x}\psi(y).
\end{equation}
Then, 
\begin{equation}
    \left[\frac{p_y^2}{2m}+\frac{1}{2}m\omega_c^2(y-l_B^2k_x)^2\right]\ket{\psi}=E_n\ket{\psi}.
\end{equation}
It has the same solution as the 1D harmonic oscillator, but with a displacement. 
\begin{equation}\label{12.26}
    E_n=\hbar\omega_c\left(n+\frac{1}{2}\right).
\end{equation}
\subsubsection{Symmetrical Gauge}
Let 
\begin{equation}
    l_B=\sqrt{\frac{\hbar}{eB}},\quad \omega_c=\frac{eB}{m},
\end{equation}
\begin{equation}
    a=\frac{1}{\sqrt{2}}\frac{l_B}{\hbar}\left(\Pi_x+\ii \Pi_y\right),\ a^\dagger=\frac{1}{\sqrt{2}}\frac{l_B}{\hbar}\left(\Pi_x-\ii \Pi_y\right).
\end{equation}
Then, 
\begin{equation}
    [a,a^\dagger]=1,\ H=\hbar\omega_c\left(a^\dagger a+\frac{1}{2}\right).
\end{equation}
Then we can derivative \eqref{12.26} quickly. 

To solve the wave function, we need choose a gauge, here we use symmetrical gauge, $(A_x,A_y)=\frac{B}{2}(-y,x)$. Let $w=x+\ii y$, $\overline{\pa }=\frac{\pa}{\pa \overline{w}}=\frac{1}{2}(\pa_x+\ii \pa_y)$. Then
\begin{equation}
    \bra{\mathbf{x}}a\ket{\psi}=-\ii \sqrt{2}l_B\left(\overline{\pa}+\frac{w}{4l_B^2}\right)\braket{\mathbf{x}}{\psi}, \bra{\mathbf{x}}a^\dagger\ket{\psi}=\ii \sqrt{2}l_B\left(\pa-\frac{\overline{w}}{4l_B^2}\right)\braket{\mathbf{x}}{\psi}.
\end{equation}
The wave function of the ground state satisfies
\begin{equation}
    \left(\overline{\pa}+\frac{w}{4l_B^2}\right)\psi_0(w,\overline{w})=0.
\end{equation}
The solution is 
\begin{equation}
    \psi_0(w,\overline{w})=\ee^{-\frac{\left|w\right|^2}{4l_B^2}}f(w,\overline{w}),
\end{equation}
where $f$ satisfies
\begin{equation}
    \overline{\pa}f=0.
\end{equation}
So, we can write $\psi_0$ as 
\begin{equation}
    \psi_0 (w,\overline{w})=f(w)\ee^{-\frac{\left|w\right|^2}{4l_B^2}}.
\end{equation}
Then 
\begin{equation}
    \psi_n(w,\overline{w})=\ee^{- \frac{\left|w\right|^2}{4l_B^2}}\left(\pa-\frac{\overline{w}}{2l_B^2}\right)^nf(w).
\end{equation}
An arbitrary $f(w)$ makes the states highly degenerate. Expand $f$ in a series,
\begin{equation}
    f(w)=\sum_{m\in \mathbb{N}}c_m w^m,
\end{equation}
and denote
\begin{equation}
    \psi_{0,m}\sim w^m \ee^{- \frac{\left|w\right|^2}{4l_B^2}}.
\end{equation}
In fact, $\psi_{0,m}$ is also the eigenstates of $L_z=\hbar(\pa w-\overline{\pa}\overline{w})$, and the eigenvalues are $m\hbar$.

$|\psi_{0,m}|^2$ take the maximum when $|w|=r_m$, where
\begin{equation}
    r_m=\sqrt{2m}l_B.
\end{equation}
Easy to note that each state has a area of $2\pi l_B^2$ greater than another.



\section{Angular Momentum}
\subsection{Infinitesimal Rotations in Quantum Mechanics}

We want to construct a rotation operator $\mathscr{D}$\footnote{The symbol $\mathscr{D}$ stems from the German word Drehung, meaning ``rotation."}. The appropriate infinitesimal operators could be
written as
\begin{equation}
    U_{\varepsilon}=1-\ii G\varepsilon
\end{equation}
with a Hermitian operator $G$. Define the angular-momentum operator
$J_k$ in such a way that the operator for an infinitesimal rotation around the $k$th axis
by angle $\dd{\varphi}$ can be obtained by letting 
\begin{equation}
    G\rightarrow \frac{J_k}{\hbar},\quad \varepsilon\rightarrow \dd{\phi}.
\end{equation}
With $J_k$ taken to be Hermitian, the infinitesimal-rotation operator is
guaranteed to be unitary and reduces to the identity operator in the limit $\dd{\phi}\rightarrow 0$. More generally, we have
\begin{equation}
    \mathscr{D}(\hat{\mathbf{n}},\dd{\phi})=1-\ii\left(\frac{\mathbf{J}\cdot\hat{\mathbf{n}}}{\hbar}\right)\dd{\phi}
\end{equation}
for a rotation about the direction characterized by a unit vector $\hat{\mathbf{n}}$ by an infinitesimal angle $\dd{\phi}$. For instance, if we are interested in a finite rotation
about the $\hat{\mathbf{n}}$-axis by angle $\phi$, we consider
\begin{equation}
    \mathscr{D}_{\hat{\mathbf{n}}}(\phi)=\lim_{N\rightarrow +\infty}\left[1-\ii\left(\frac{\mathbf{J}\cdot\hat{\mathbf{n}}}{\hbar}\right)\frac{\phi}{N}\right]^N=\exp\left[-\ii\left(\frac{\mathbf{J}\cdot\hat{\mathbf{n}}}{\hbar}\right)\phi\right].
\end{equation}
Taking $\phi=\varepsilon$, the first three term is 
\begin{equation}
    \mathscr{D}_{\hat{\mathbf{n}}}(\varepsilon)\approx 1-\ii\left(\frac{\mathbf{J}\cdot\hat{\mathbf{n}}}{\hbar}\right)\varepsilon-\frac{1}{2!}\left(\frac{\mathbf{J}\cdot\hat{\mathbf{n}}}{\hbar}\right)^2\varepsilon^2.
\end{equation}
Let $\hat{\mathbf{n}}$ be $\hat{\mathbf{x}}$ and $\hat{\mathbf{y}}$, by the properties of rotation, $\mathscr{D}$ need to satisfy
\begin{equation}
    \left[\mathscr{D}_x(\varepsilon),\mathscr{D}_y(\varepsilon)\right]=\mathscr{D}_z(\varepsilon^2)-1.
\end{equation}
So, 
\begin{equation}\label{13.7}
    [J_x,J_y]=\ii \hbar J_z.
\end{equation}
In general,
\begin{equation}
    [J_i,J_k]=\ii \hbar \varepsilon_{ijk}J_k.
\end{equation}
By the meaning of rotation, we can also know that for any scalar $a$ and vector $v_i$,
\begin{equation}
    \left[J_i,a\right]=0,\quad \left[J_i,v_j\right]=\ii \hbar \varepsilon_{ijk}v_k.
\end{equation}


\subsection{Orbital Angular Momentum}
Orbital angular momentum is defined as
\begin{equation}
    \mathbf{L}=\mathbf{x}\times \mathbf{p}.
\end{equation}
Easy to check that $\mathbf{L}$ satisfies \eqref{13.7}.
Expand $\mathbf{L}^2$:
\begin{equation}\label{13.11}
\begin{aligned}
\mathbf{L}^2 &= \sum_{ijlmk} \varepsilon_{ijk}x_i p_j \varepsilon_{lmk}x_l p_m \\
&= \sum_{ijlm} (\delta_{il}\delta_{jm} - \delta_{im}\delta_{jl})x_i p_j x_l p_m \\
&= \sum_{ijlm} [\delta_{il}\delta_{jm}x_i (x_l p_j - \ii\hbar\delta_{jl})p_m - \delta_{im}\delta_{jl}x_i p_j(p_m x_l + \ii\hbar\delta_{lm})]  \\
&= \mathbf{x}^2 \mathbf{p}^2 - \ii\hbar \mathbf{x} \cdot \mathbf{p} - \sum_{ijlm} \delta_{im}\delta_{jl}[x_i p_m(x_l p_j - \ii\hbar\delta_{jl}) + \ii\hbar\delta_{lm}x_i p_j] \\
&= \mathbf{x}^2 \mathbf{p}^2 - (\mathbf{x} \cdot \mathbf{p})^2 + \ii\hbar \mathbf{x} \cdot \mathbf{p}.
\end{aligned}
\end{equation}
We have 
\begin{equation}
    \left[L_i,H\right]=0,\quad \left[L^iL_i,H\right]=0,\quad \left[L^iL_i,L_j\right]=0.
\end{equation}
So we can get the eigen value of $L_z, \mathbf{L}^2, H$ at the same time.
\begin{equation}
    \bra{\mathbf{x}}\mathbf{L}\ket{\alpha}=-\ii \hbar \mathbf{x}\times\nabla\braket{\mathbf{x}}{\alpha}.
\end{equation}
Under spherical coordinates, the \href{run:Nabla Operator.pdf alias}{nabla operator} can be written as\footnote{$\mathbf{p}$ represent a displacement, it always acts like a gradient.}
\begin{equation}
    \nabla=\pdv{r}\hat{\mathbf{r}}+\frac{1}{r}\pdv{\theta}\hat{\mathbf{\theta}}+\frac{1}{r\sin\theta}\pdv{\phi}\hat{\mathbf{\phi}}.
\end{equation}
One has,
\begin{equation}
    \mathbf{x}=r \hat{\mathbf{r}},
\end{equation}
so, 
\begin{equation}
    \mathbf{x}\times\nabla=\pdv{\theta}\hat{\mathbf{\phi}}-\frac{1}{\sin\theta}\pdv{\phi}\hat{\mathbf{\theta}}.
\end{equation}
Then, project on $\hat{\mathbf{x}},\hat{\mathbf{y}},\hat{\mathbf{z}}$, we obtain
\begin{eqnarray}
    &\bra{\mathbf{x}}L_z\ket{\alpha}=&-\ii \hbar \pdv{\phi}\braket{\mathbf{x}}{\alpha},\\
    &\bra{\mathbf{x}}L_x\ket{\alpha}=&-\ii \hbar \left(-\sin \phi \pdv{\theta}-\cot\theta\cos\phi \pdv{\phi}\right)\braket{\mathbf{x}}{\alpha},\\
    &\bra{\mathbf{x}}L_y\ket{\alpha}=&-\ii \hbar \left(\cos \phi \pdv{\theta}-\cot\theta\sin\phi \pdv{\phi}\right)\braket{\mathbf{x}}{\alpha},\\
    &\bra{\mathbf{x}}L_\pm\ket{\alpha}=&-\ii\hbar \ee^{\pm \ii \phi}\left(\pm \ii\frac{\pa}{\pa \theta}-\cot \theta\frac{\pa}{\pa \phi}\right)\braket{\mathbf{x}}{\alpha}.\label{13.20}
\end{eqnarray}
Where, $L_\pm=L_x\pm \ii L_y$. \eqref{13.11} gives the fact that 
\begin{equation}
    \bra{\mathbf{x}}\mathbf{L}^2\ket{\alpha}=-r^2\hbar^2\nabla^2_{\theta,\phi}\braket{\mathbf{x}}{\alpha}.
\end{equation}
$\nabla_{\theta,\phi}$ is the laplacian in spherical coordinates, but without the term\footnote{Term of $r$ is $\frac{1}{r^2}\frac{\pa}{\pa r}\left(r^2\frac{\pa}{\pa r}\cdot\right)$. This is equivalent to $\frac{1}{r}\frac{\pa^2}{\pa r^2}\left(r\ \cdot \ \right)$} of $r$.


\subsection{Eigen Value}
We now look for the simultaneous eigenkets of $\mathbf{J}^2$ and $J_z$. We denote the eigen-values of $\mathbf{J}^2$ and $J_z$ by $a$ and $b$, respectively:
\begin{equation}
    \mathbf{J}^2\ket{a,b}=a\ket{a,b},\quad J_z\ket{a,b}=b\ket{a,b}.
\end{equation}
Consider
\begin{equation}
    J_\pm:=J_x\pm \ii  J_y,
\end{equation}
then, 
\begin{equation}\label{13.22}
    J_-=J_+^\dagger, \quad \mathbf{J}^2=J_z^2+\frac{1}{2}\{J_+,J_-\}.\quad J_-J_+ =\mathbf{J}^2- J_z^2 -\hbar J_z,
\end{equation}
\begin{equation}
    [J_+,J_-]=2\hbar J_z,\quad [J_z,J_\pm]=\pm\hbar J_\pm,\quad [\mathbf{J}^2,J_\pm]=0.
\end{equation}
\begin{equation}
    J_z\left(J_\pm\ket{a,b}\right)=\left(b\pm\hbar\right)\left( J_\pm\ket{a,b}\right).
\end{equation}
So, we call $J_\pm$ the \textbf{ladder operators}.
\begin{equation}
    \mathbf{J}^2\left(J_\pm\ket{a,b}\right)=J_\pm \mathbf{J}^2\ket{a,b}=a\left(J_\pm\ket{a,b}\right).
\end{equation}
So, 
\begin{equation}
    J_\pm\ket{a,b}=c_\pm\ket{a,b\pm \hbar}.
\end{equation}
Then there must exists $b_\mathrm{max}$ and $b_\mathrm{min}$, such that\footnote{By \eqref{13.22}} 
\begin{equation}
    a=b_\mathrm{max}\left(b_\mathrm{max}+\hbar\right)=b_\mathrm{min}\left(b_\mathrm{min}-\hbar\right).
\end{equation}
We can infer that 
\begin{equation}
   - b_\mathrm{max}=b_\mathrm{min},
\end{equation}
with $b_\mathrm{max}$ is positive, and that the allowed values of $b$ lie within
\begin{equation}
    b_\mathrm{min}\le b\le b_\mathrm{max}.
\end{equation}
\begin{equation}
    b_\mathrm{max}=\frac{n\hbar}{2}\equiv j\hbar,
\end{equation}
where $j$ is either an integer or a half-integer\footnote{If it represent the orbital angular momentum, we will denote $j$ as $l$, and $l$ can only take integer number, since the following will show the factor $\ee^{\ii l\phi}$, and it must admit $2\pi$ as a period.}, then 
\begin{equation}
    a=\hbar^2 j(j+1).
\end{equation}
Let us also define $m$ such that 
\begin{equation}
    b\equiv m\hbar.
\end{equation}
The allowed $m$-values for a given $j$ are
\begin{equation}
    m=\underset{2j+1 \text{ states}}{\underbrace{-j,-j+1,\dots,j-1,j}}.
\end{equation}
Instead of $\ket{a,b}$, it is more convenient to denote a simultaneous eigenket of $\mathbf{J}^2$
and $J_z$ by $\ket{j,m}$.
\begin{equation}\label{13.34}
    \mathbf{J}^2\ket{j,m}=\hbar^2 j(j+1)\ket{j,m},\quad J_z\ket{j,m}=m\hbar\ket{j,m}.
\end{equation}
Then we can deduce that 
\begin{equation}\label{13.37}
    J_\pm\ket{j,m}=\sqrt{\left(j\mp m\right)\left(j\pm m+1\right)}\hbar\ket{j,m},
\end{equation}
\textbf{Important result}: If $[K,\mathbf{J}]=0$, then $K\ket{j,m}$ is also a eigenket of $\mathbf{J}^2$ and $J_z$. So,
\begin{equation}
    \bra{j',m'}K\ket{j,m}=\delta_{j'j}\delta_{m'm}f(j,m).
\end{equation}
By using $\mathbf{J}_{\pm}$, we can prove that 
\begin{equation}
    \bra{j,m+1}K\ket{j,m+1}=\bra{j,m}K\ket{j,m}.
\end{equation}

\subsection{Representations of the Rotation Operator}
If an arbitrary $y$-axis is rotated around the arbitrary $z$-axis by $\alpha$ to become $y'$, then for any angle $\beta$, then\footnote{$R$ also means rotation.}
\begin{equation}
    R_{y'}(\beta)=R_z(\alpha)R_y(\beta)R^{-1}_z(\alpha).
\end{equation}
If we use the Euler Rotations\footnote{This figure is from \textit{Modern Quantum Mechanics}}, then
\begin{equation}
    R(\alpha,\beta,\gamma)\equiv R_{z'}(\gamma)R_{y'}(\beta)R_z(\alpha)=R_z(\alpha)R_{y}(\beta)R_{z}(\gamma).
\end{equation}
\begin{figure}[H]
    \centering
    \includegraphics[width=0.65\textwidth]{figures/Euler Rotation.png}
    \caption{Euler Rotations}
\end{figure}
Having obtained the matrix elements of $J_z$ and $J_\pm$, we are now in a position to
study the matrix elements of the rotation operator $\mathscr{D}(R)$. If a rotation $R$ is specified
by $\hat{\mathbf{n}}$ and $\phi$, we can define its matrix elements by
\begin{equation}
    \mathscr{D}^{(j)}_{m'm}(R)=\bra{j,m'}\exp\left(\frac{-\ii \mathbf{J}\cdot\hat{\mathbf{n}}\phi}{\hbar}\right)\ket{j,m}.
\end{equation}
These matrix elements are sometimes called \textbf{Wigner functions}.
In Euler Rotations, the rotation operator is defined by
\begin{equation}
    \begin{aligned}
        &\mathscr{D}^{(j)}_{m'm}(\alpha,\beta,\gamma)\\
        =&\bra{j,m'}\exp\left(\frac{-\ii J_z \alpha}{\hbar }\right)\exp\left(\frac{\ii J_y \beta}{\hbar}\right)\exp\left(\frac{-\ii J_z \gamma}{\hbar}\right)\ket{j,m}\\
        =&\ee ^{-\ii\left( m' \alpha+m\gamma\right)}\bra{j,m'}\exp\left(\frac{-\ii J_y \beta}{\hbar}\right)\ket{j,m}.
    \end{aligned}
\end{equation}
We denote nontrivial part as 
\begin{equation}
    d^{(j)}_{m'm}(\beta)=\bra{j,m'}\exp\left(\frac{-\ii J_y \beta}{\hbar}\right)\ket{j,m}.
\end{equation}
Since 
\begin{equation}
    \left[\mathbf{J}^2,\mathscr{D}(R)\right]=0,
\end{equation}
any state $\ket{j,m}$ after a rotation $R$ is also an eigenket of $\mathbf{J}^2$, and its eigenvalue is still $j(j+1)\hbar^2$.

To find the amplitude for being found in $\ket{j,m}$ , we simply expand the rotated state as follows:
\begin{equation}
    \mathscr{D}(R)\ket{j,m}=\sum_{m'}\ket{j,m'}\bra{j,m'}\mathscr{D}(R)\ket{j,m}=\sum_{m'}\ket{j,m'}\mathscr{D}^{(j)}_{m'm}(R).
\end{equation}
\singleline
\begin{theorem}[Wigner]
    Given an operator $R$, if for any state $\ket{\psi}$, $\ket{\phi}$, $\left|\braket{R\psi}{R\phi}\right|$ is held, then $R$ is unitary or anti-unitary.
    
\end{theorem}
\singleline


\subsection{Spherical Harmonics}
\footnote{\href{run:Spherical Functions.pdf alias}{Spherical Functions.}}
Let us consider a problem with spherical symmetry, we can consider
\begin{equation}
    \bra{\hat{\mathbf{n}}}\ket{l,m}=Y_l^m(\hat{\mathbf{n}})=Y_l^m\left(\theta,\phi\right),
\end{equation}
where we have defined a \textbf{direction eigenket} $\ket{\hat{\mathbf{n}}}$.

By \eqref{13.34}, we have 
\begin{equation}\label{13.44}
    -\ii \hbar \frac{\pa}{\pa \phi}Y_l^m\left(\theta,\phi\right)=m\hbar Y_l^m\left(\theta,\phi\right),
\end{equation}
\begin{equation}
    \left[\frac{1}{\sin \theta}\frac{\pa}{\pa \theta}\left(\sin\theta\frac{\pa}{\pa \theta}\right)+\frac{1}{\sin^2\theta}\frac{\pa^2}{\pa \phi^2}+l\left(l+1\right)\right]Y_l^m=0.
\end{equation}
By 
\begin{equation}
    \bra{l',m'}\ket{l,m}=\delta_{ll'}\delta_{mm'},
\end{equation}
we obtain,
\begin{equation}\label{13.48}
    \int_{0}^{2\pi}\dd{\phi}\int_{-1}^{1}\dd{(\cos\theta)}{Y_{l'}^{m'}}^*\left(\theta,\phi\right)Y^m_l\left(\theta,\phi\right)=\delta_{ll'}\delta_{mm'}.
\end{equation}
\eqref{13.44} implies that the $\phi$-independence $Y_l^m\left(\theta,\phi\right)$ must behave like $\ee^{\ii m \phi}$. By \eqref{13.20},
\begin{equation}
    \left[\ii \frac{\pa }{\pa \theta}-\cot\theta\frac{\pa}{\pa \phi}\right]\braket{\hat{\mathbf{n}}}{l,l}=0.
\end{equation}
So, 
\begin{equation}
    Y_l^l\left(\theta,\phi\right)=c_l\ee^{\ii l\phi}\sin^l\theta.
\end{equation}
Use \eqref{13.48} to normalize,
\begin{equation}
    \int_{0}^{\pi}\sin^{2l}\theta \sin\theta \dd{\theta}=B\left(l+1,\frac{1}{2}\right)=\frac{\Gamma\left(l+1\right)\Gamma\left(\frac{1}{2}\right)}{\Gamma\left(l+\frac{3}{2}\right)}.
\end{equation}
Then we can use the ladder operator to get $Y_l^m$. Check details in the reference.



\subsection{Schwinger’s Oscillator Model of Angular Momentum}
Consider a 2D harmonic oscillator $H=\hbar \omega(a_1^\dagger a_1+a_2^\dagger a_2)$ exhibiting the SU(2) symmetry. We define,
\begin{equation}
    J_\mu=\frac{1}{2}a^\dagger_\alpha\left(\sigma^\mu\right)^\alpha_{\ \beta}a^\beta,
\end{equation}
where $\sigma^\mu$ is one of the \href{run:Pauli Matrix.pdf alias}{Pauli matrix} with $\mu=1,2,3$, $\{\alpha,\beta\}\subseteq\{1,2\}$. We can prove that 
\begin{equation}
    [J_\mu,J_\nu]=\ii \varepsilon_{\mu\nu\rho}J_\rho.
\end{equation}
If we let $2J=a^\dagger_\alpha a^\alpha$, then
\begin{equation}
    J^\mu J_\mu=J(J+1).
\end{equation}
And the state can be represented as:
\begin{equation}
    \ket{j,m}=\frac{(a^\dagger_1)^{j+m}}{\sqrt{(j+m)!}}\frac{(a_2^\dagger)^{j-m}}{\sqrt{(j-m)!}}\ket{0,0}.
\end{equation}
It satisfies \eqref{13.34} and \eqref{13.37}.



\subsection{Addition of Angular Momenta}
Consider two independent state $\ket{\alpha}$, $\ket{\beta}$, we can see them as a state $\ket{\alpha,\beta}$\footnote{The following is tensor product, but in many physics books they mess up with direct product.},
\begin{equation}
    \ket{\alpha,\beta}=\ket{\alpha}\otimes\ket{\beta},
\end{equation}
Consider the rotation 
\begin{equation}
    \mathscr{D}(R)=\mathscr{D}_1(R)\otimes \mathscr{D}_2(R)=\exp\left(\frac{-\ii \mathbf{J}_1\cdot\hat{\mathbf{n}}\phi}{\hbar}\right)\otimes \exp\left(\frac{-\ii \mathbf{J}_2\cdot\hat{\mathbf{n}}\phi}{\hbar}\right).
\end{equation}
Let $\phi=\varepsilon$, and $\mathscr{D}(R)=\exp\left(-\ii \mathbf{J}\cdot\hat{\mathbf{n}}\phi/\hbar\right)$ we can get
\begin{equation}\label{13.57}
    \mathbf{J}=\mathbf{J}_1\otimes 1+1\otimes\mathbf{J}_2.
\end{equation}
When we are talking about\footnote{The computing law are very similar, so many other places always write like this.}
\begin{equation}\label{13.58}
    \mathbf{J}=\mathbf{J}_1+\mathbf{J}_2,
\end{equation}
we should understand it as \eqref{13.57}. 
Easy to check that \eqref{13.58} satisfies the commutation relation of angular momentum. But neither $\mathbf{J}_1+\mu\mathbf{J}_2$ nor $\lambda\left(\mathbf{J}_1+\mathbf{J}_2\right)$ ($\mu,\lambda\neq1$).

Also, we define 
\begin{equation}
    J_x=J_{1x}\otimes 1+1\otimes J_{2x},\quad J_y=J_{1y}\otimes 1+1\otimes J_{2y},\quad J_z=J_{1z}\otimes 1+1\otimes J_{2z},
\end{equation}
\begin{equation}
    J_+=J_{1+}\otimes 1+1\otimes J_{2+},\quad J_-=J_{1-}\otimes 1+1\otimes J_{2-},
\end{equation}
\begin{equation}
    \mathbf{J}^2=J_x^2+J_y^2+J_z^2.
\end{equation}

A calculate example\footnote{Attention: $A\otimes B+C\otimes D\overset{?}{=}(A+C)\otimes (B+D)$. But this is true: $A\otimes C+ B\otimes C=(A+B)\otimes C$. }:
\begin{equation}
    (A\otimes B)(C\otimes D)=(AC)\otimes (BD).
\end{equation}
\begin{equation}
    J_z^2= J_{1z}^2\otimes 1+1\otimes J_{2z}^2+2J_{1z}\otimes J_{2z}.
\end{equation}
So we can also write $\mathbf{J}^2$ into the form of
\begin{equation}
    \mathbf{J}^2=\mathbf{J}_1^2\otimes 1+1\otimes \mathbf{J}_2^2+2J_{1z}\otimes J_{2z}+J_{1+}\otimes J_{2-}+J_{1-}\otimes J_{2+}.
\end{equation}

\subsubsection{Clebsch-Gordan Coefficients}

As for the choice of base kets, since $[\mathbf{J}^2,J_{1,2z}]\neq0$, we have two options: 
$$\ket{j_1j_2; jm}\text{ and }\ket{j_1j_2;m_1m_2}.$$
We connect them with Clebsch-Gordan coefficients $\braket{j_1j_2m_1m_2}{j_1j_2;jm}$:
\begin{equation}
    \ket{j_1 j_2 ;j m}= \sum_{m_1, m_2}  \ket{j_1j_2 ;m_1m_2 } \braket{j_1j_2m_1m_2}{j_1j_2;jm} .
\end{equation}

We figure out some properties about CG coefficients:
\newline
(1) CG coefficients vanish unless
\begin{equation}
    m=m_1+m_2,
\end{equation}
because
\begin{equation}
    \begin{aligned}
        0=&\bra{j_1j_2;m_1m_2}(J_z-J_{1z}-J_{2z})\ket{j_1j_2;jm}\\
        =&(m-m_1-m_2)\braket{j_1j_2;m_1m_2}{j_1j_2;jm}.
    \end{aligned}
\end{equation}
(2) The coefficients vanish unless
\begin{equation}
    |j_1-j_2|\leq j\leq j_1+j_2.
\end{equation}
This is based on our choice of base kets, just for convenience, it has already provided a complete bases\footnote{Check the dimension yourself.}. In addition, we even choose CG coefficients to be real numbers. 
\newline
(3) Recursive relations 





\section{Discrete Symmetry}
\subsection{Wigner Theorem}
\singleline
\begin{theorem}[Wigner]
    Given an operator $R$, if for any state $\ket{\psi}$, $\ket{\phi}$, $\left|\braket{R\psi}{R\phi}\right|$ is held, then $R$ is unitary or anti-unitary\footnote{Review \ref{4.2} first.}.
\end{theorem}
\singleline
\begin{quotation}
    Let $\mathbb{H}$ denote the Hilbert space describing a system, with its inner product denoted by $\langle \cdot, \cdot \rangle$, and let $\mathbb{P}\mathbb{H}$ denote the corresponding projective space (the set of all one-dimensional subspaces of $\mathbb{H}$). The reason for using $\mathbb{P}\mathbb{H}$ is that its points correspond bijective to physical states. The inner product $\langle \cdot, \cdot \rangle$ on $\mathbb{H}$ induces a metric $d$ on $\mathbb{P}\mathbb{H}$ (the Fubini--Study metric). It is easy to see that a unitary or anti-unitary operator $K : \mathbb{H} \rightarrow \mathbb{H}$ (where anti-unitary means $\langle Kv, Kw \rangle = \langle w, v \rangle$) induces a homeomorphism from $\mathbb{P}\mathbb{H}$ to $\mathbb{P}\mathbb{H}$ that preserves the metric $d$, meaning $d(Kx, Ky) = d(x, y)$. Wigner's theorem states that any homeomorphism of $\mathbb{P}\mathbb{H}$ onto itself that preserves the metric $d$ is necessarily induced by some unitary or anti-unitary operator on $\mathbb{H}$.


\textbf{Theorem (Wigner):} If the dimension of $\mathbb{H}$ is greater than or equal to 2, and $U : \mathbb{P}\mathbb{H} \rightarrow \mathbb{P}\mathbb{H}$ is a homeomorphism preserving the metric $d$, i.e., $d(Ux, Uy) = d(x, y)$, then there exists a unitary or anti-unitary operator $\mathcal{U}$ on $\mathbb{H}$ such that $\mathcal{U}$ induces $U$. If $\mathcal{V}$ also induces $U$, then $\mathcal{V} = e^{i\theta} \mathcal{U}$, where $\theta \in \mathbb{R}$.\hfill \href{https://zhuanlan.zhihu.com/p/638385348?share_code=oQHLdmPp3g4I&utm_psn=1972351456918115809}{---\textit{Reference}}
\end{quotation}
\subsection{Parity Transformation}
Parity operator $\pi$ will changes a right-handed system into a left-handed system. Somewhere, we denote any ket $\ket{\alpha}$ after action by $\pi$ as $\ket{\alpha^\pi}$, but in most of my habits, I will just write $\ket{\pi\alpha}$.
\begin{equation}
    \ket{\pi\alpha}:=\pi\ket{\alpha}
\end{equation}
Consider the physical meaning, we require
\begin{align}
    \braket{\pi\alpha}{\pi\alpha}&=\braket{\alpha}{\alpha},\label{15.2}\\
    \expval{\mathbf{x}}{\pi\alpha}&=-\expval{\mathbf{x}}{\alpha}.
\end{align}

\ref{15.2} implies that $\pi$ is whether unitary or anti-unitary. 

Since the expectation value is a real number, and $\pi$ keep the module invariant, 
\begin{equation}
    \expval{\mathbf{x}}{\pi\alpha}=\expval{\pi^{-1}\mathbf{x}\pi}{\alpha}.
\end{equation}

Then we will use $\bra{\alpha}\pi^{-1} \mathbf{x}\pi\ket{\alpha}=-\bra{\alpha}\mathbf{x}\ket{\alpha}$ to prove $\pi^{-1} \mathbf{x}\pi=-\mathbf{x}$. Since $\ket{\alpha}$ is arbitrary, let $\ket{\alpha}=\ket{\psi}+\ket{\phi}$. Then, we can deduce that 
\begin{equation}
    \mathrm{Re}\left(\bra{\psi}\pi^{-1}\mathbf{x}\pi\ket{\phi}\right)=-\mathrm{Re}\left(\bra{\psi}\mathbf{x}\ket{\phi}\right).
\end{equation} 
Let $\ket{\alpha}=\ket{\psi}+\ii \ket{\phi}$, then,
\begin{equation}
    \mathrm{Im}\left(\bra{\psi}\pi^{-1}\mathbf{x}\pi\ket{\phi}\right)=-\mathrm{Im}\left(\bra{\psi}\mathbf{x}\ket{\phi}\right).
\end{equation}
So, for any $\ket{\psi}$, $\ket{\phi}$, 
\begin{equation}
    \bra{\psi}\pi^{-1}\mathbf{x}\pi\ket{\phi}=-\bra{\psi}\mathbf{x}\ket{\phi}.
\end{equation}
Which means 
\begin{equation}
    \pi^{-1}\mathbf{x}\pi=-\mathbf{x},\quad \mathbf{x}\pi=-\pi\mathbf{x}.
\end{equation}


Then we derive the effect $\pi$ act on momentum $p$. Let us start from position translation. We have
\begin{equation}
    \pi\mathscr{T}(\dd{\mathbf{x}'})=\mathscr{T}(-\dd{\mathbf{x}'})\pi,
\end{equation}
so,
\begin{equation}
    \pi^{-1}\mathbf{p\pi=-\mathbf{p}},\ \{\pi,\mathbf{p}\}=0.
\end{equation}

Easy to check that 
\begin{equation}
 \pi^{-1}\ii \hbar \pi= \pi^{-1}[\mathbf{x},\mathbf{p}]\pi=[\mathbf{x},\mathbf{p}]=\ii \hbar.
\end{equation}
So, $\pi$ is unitary. Then we can define $\pi^\dagger$, and $\pi^\dagger\pi=1$.

Note that 
\begin{equation}
    \mathbf{x}\pi\ket{\mathbf{x}'}=-\pi\mathbf{x}\ket{\mathbf{x'}}=(-\mathbf{x}')\pi\ket{\mathbf{x}'}.
\end{equation}
So $\pi\ket{\mathbf{x}'}=\ee^{\ii \delta}\ket{-\mathbf{x}'}$. It is customary to take $\ee^{\ii \delta} = 1$ by convention. Then $\pi^2=1$. Hence,
\begin{equation}
    \pi^{-1}=\pi^\dagger=\pi.
\end{equation}
Its eigen-value can only be $\pm 1$.

In geometry, reflection is commutable with rotation. In the language of operators,
\begin{equation}
    \pi\mathscr{D}(R)=\mathscr{D}(R)\pi.
\end{equation}
So,
\begin{equation}
    \pi^\dagger\mathbf{J}\pi=\mathbf{J},\ [\pi,\mathbf{J}]=0.
\end{equation}

Now, we consider the wave-function under parity transformation. For any state $\ket{\psi}$, let the its state after parity transformation be $\ket{\psi'}$, then we have
\begin{equation}
    \psi'(\mathbf{x})=\braket{\mathbf{x}}{\psi'}=\bra{\mathbf{x}}\pi\ket{\psi}=\bra{-\mathbf{x}}\ket{\psi}=\psi(-\mathbf{x}).
\end{equation}
If $\ket{\psi}$ is an eigen-state of $\pi$, $\pi\ket{\psi}=\pm\ket{\psi}$, then
\begin{equation}
    \psi(\mathbf{x})=\pm \psi(-\mathbf{x})\begin{cases}
        \text{even parity,}\\
        \text{odd parity.}
    \end{cases}
\end{equation}
So for 1D harmonic oscillator,
\begin{equation}
    \psi_n(-x)=(-)^n\psi_n(x).
\end{equation}
For angular momentum eigenstates $Y_{l,m}(\hat{\mathbf{n}})$
\begin{equation}
    Y_{lm}(-\hat{\mathbf{n}})=Y_{lm}(\pi-\theta,\pi+\varphi)=(-)^l Y_{lm}(\theta,\varphi).
\end{equation}
\singleline
\begin{theorem}
    Suppose 
    \begin{equation*}
        [H,\pi]=0
    \end{equation*}
    and $\ket{n}$ is a nondegenerate eigenket of $H$ with eigenvalue $E_n$: 
    \begin{equation*}
        H\ket{n}=E_n\ket{n};
    \end{equation*}
    then $\ket{n}$ is also a parity eigenket.
\end{theorem}
\singleline
\begin{proof}
    Note that $\frac{1}{2}(1\pm\pi)\ket{n}$ is a parity eigenket with eigenvalues $\pm1$. But this is also an energy eigenket with eigenvalue $E_n$, which means it represent the same state as $\ket{n}$.
\end{proof}

\subsection{Time-Reversal Symmetry}
First we claim that any anti-unitary operator can be written as
\begin{equation}
    \theta=UK,
\end{equation}
where $U$ is a unitary operator, and $K$ is the complex-conjugate operator that forms
the complex conjugate of any coefficient that multiplies a ket.



\section{Approximation Methods}
\subsection{{\small Time-independent Perturbation Theory}: {\small Non-degenerate Case}}
Consider 
\begin{equation}
    H=H_0+\lambda V,
\end{equation}
where $\lambda\ll1$, and we have known the eigenvalues and eigenkets of $H_0$. Then we want to know the eigenvalues and eigenkets of $H$.
Let 
\begin{equation}
    \Delta_n=E_n-E_n^{(0)},
\end{equation}
then Schrödinger equation gives
\begin{equation}
    (E_n^{(0)}-H_0)\ket{n}=(\lambda V-\Delta_n)\ket{n}.
\end{equation}
For convenience, we define the projection operator and an operator like inverse of $(E_n^{(0)}-H_0)$:
\begin{equation}
    \phi_n := 1-\ket*{n^{(0)}}\bra*{n^{(0)}}=\sum_{m\neq n}\ket*{m^{(0)}}\bra*{m^{(0)}},
\end{equation}
\begin{equation}
    \frac{\phi_n}{E_n^{(0)}-H_0} := \sum_{m\neq n}\frac{\ket*{m^{(0)}}\bra*{m^{(0)}}}{E_n^{(0)}-E_m^{(0)}}.
\end{equation}
We define $\phi_n$ aim at projecting out the component of $\ket*{n^{(0)}}$, eliminating the singularity of $(E_n^{(0)}-H_0)^{-1}$.

Now, we have
\begin{equation}
    \ket{n}=\frac{\phi_n}{E_n^{(0)}-H_0}(\lambda V-\Delta_n)\ket{n}+\ket*{n^{(0)}}\braket*{n^{(0)}}{n}.
\end{equation}

Note that 
\begin{equation}
    \bra*{n^{(0)}}(E_n^{(0)}-H_0)\ket{n}=0.
\end{equation}
So,
\begin{equation}
    \Delta_n\braket*{n^{(0)}}{n}=\lambda \bra*{n^{(0)}}V\ket{n}.
\end{equation}
Since there's just a common multiplicative factor, we can normalize $\ket{n}$ later, and now we let $\braket*{n^{(0)}}{n}=1$. Then, we can set 
\begin{equation}
    \ket{n}=\ket*{n^{(0)}}+\lambda \ket*{n^{(1)}}+\lambda^2 \ket*{n^{(2)}}+\cdots,
\end{equation}
\begin{equation}
    \Delta_n=\lambda E_n^{(1)}+\lambda^2 E_n^{(2)}+\cdots.
\end{equation}
equating the coefficient of various powers of $\lambda$, we obtain
\begin{equation}
    \Delta_{n}^{(k)}=\bra*{n^{(0)}}V\ket*{n^{(k-1)}},\ k=1,2,\ldots,
\end{equation}
Also,
\begin{equation}
    \ket*{n^{(k)}}=\frac{\phi_n}{E_n^{(0)}-H_0}\left[\left(V-\Delta_n^{(1)}\right)\ket*{n^{(k-1)}}-\sum_{j=2}^{k}\Delta_n^{(j)}\ket*{n^{(k-j)}}\right],\ k=1,2,\ldots.
\end{equation}
Let 
\begin{equation}
    V_{nk}:=\bra*{n^{(0)}}V\ket*{k^{(0)}},
\end{equation}
let us simplify the first and second order corrections:
\begin{equation}
    \Delta_n^{(1)}=V_{nn},
\end{equation}
So,
\begin{equation}
    \ket*{n^{(1)}}=\sum_{m\neq n}\frac{V_{mn}}{E_n^{(0)}-E_m^{(0)}}\ket*{m^{(0)}},
\end{equation}
\begin{equation}
    \Delta_n^{(2)}=\sum_{m\neq n}\frac{|V_{mn}|^2}{E_n^{(0)}-E_m^{(0)}}.
\end{equation}
\begin{equation}
    \ket*{n^{(2)}}=\sum_{m\neq n}\left[\sum_{l\neq n}\frac{V_{ml}V_{ln}}{(E_n^{(0)}-E_m^{(0)})(E_n^{(0)}-E_l^{(0)})}-\frac{V_{nn}V_{mn}}{(E_n^{(0)}-E_m^{(0)})^2}\right]\ket*{m^{(0)}}.
\end{equation}
Thus, up to second order in $\lambda$, we have
\begin{equation}
    E_n\approx E_n^{(0)}+\lambda V_{nn}+\lambda^2\sum_{m\neq n}\frac{|V_{mn}|^2}{E_n^{(0)}-E_m^{(0)}},
\end{equation}
\begin{equation}
    \ket{n}\approx \ket*{n^{(0)}}+\lambda \sum_{m\neq n}\frac{V_{mn}}{E_n^{(0)}-E_m^{(0)}}\ket*{m^{(0)}}.
\end{equation}
Second order correction of energy at ground state always show minus sign.

It is time to normalize $\ket{n}$. We define
\begin{equation}
    \ket{n}_N=Z_n^{1/2}\ket{n},\ Z_n^{1/2}=\braket*{n^{(0)}}{n}_N.
\end{equation}
Since $\bra*{n^{(0)}}\ket*{n^{(k)}}=0$, if $k\ge 1$,
\begin{align}
    Z_n^{-1}&=1+\lambda^2\bra*{n^{(1)}}\ket*{n^{(1)}}+\mathcal{O}(\lambda^3)\\
    &=1+\lambda^2\sum_{m\neq n}\frac{|V_{mn}|^2}{(E_n^{(0)}-E_m^{(0)})^2}+\mathcal{O}(\lambda^3).
\end{align}
\begin{equation}\label{16.23}
    Z_n=1-\lambda^2\sum_{m\neq n}\frac{|V_{mn}|^2}{(E_n^{(0)}-E_m^{(0)})^2}+\mathcal{O}(\lambda^3).
\end{equation}
The second term in \eqref{16.23} is to be understood as the probability for “leakage”
to states other than $\ket*{n^{(0)}}$ . Notice that $Z_n$ is less than $1$, as expected on the basis
of the probability interpretation for $Z$.

In fact, we have (not only up to second order)
\begin{equation}
    Z_n=\frac{\pa E_n}{\pa E_n^{(0)}}.
\end{equation}
\subsection{{\small Time-independent Perturbation Theory: Degenerate Case}}
This is the case where some subtraction of eigenvalues not much greater than perturbation. So we need to deal with the part out of hypothesis in the previous case. We define a projection operator $P_0$ that project a state to $\{\ket*{m^{(0)}}\}$, where the eigen-values are very close such that we do not need to consider their difference while dealing with the perturbation. We denote this subspace as $D$ (Without losing of generality, we concentrate on one subspace.) For convenience, we also define $P_1:=1-P_0$.
For any ket in $D$,
\begin{equation}
    \ket*{l^{(0)}}=\sum_{m\in D}\braket*{m^{(0)}}{l^{(0)}}\ket*{m^{(0)}}.
\end{equation}
Different from the reference book, I will estimate the order of difference between eigen-energy in $D$. And we choose $\ket{n}\in D$.

By projection and orthogonality, it is easy to get
\begin{equation}\label{16.26}
    (E-H_0-\lambda P_0 V)P_0\ket{n}-\lambda P_0VP_1\ket{n}=0.
\end{equation}
\begin{equation}\label{16.27}
    (E-H_0-\lambda P_1 V)P_1\ket{n}-\lambda P_1VP_0\ket{n}=0.
\end{equation}
By \eqref{16.27},
\begin{equation}\label{16.28}
    P_1\ket{n}=P_1\frac{\lambda}{E-H_0-\lambda P_1 V P_1}P_1VP_0\ket{n}.
\end{equation}
Let 
\begin{equation}
    \ket{n}=\ket*{n^{(0)}}+\lambda \ket*{n^{(1)}}+\mathcal{O}(\lambda^2),
\end{equation}
\begin{equation}
    E=E_n^{(0)}+\lambda \Delta_n^{(1)}+\mathcal{O}(\lambda^2),
\end{equation}
Then,
\begin{equation}
    P_1\ket*{n^{(1)}}=\sum_{k\notin D}\frac{V_{kl}\ket*{k^{(0)}}}{E_n^{(0)}-E_k^{(0)}}.
\end{equation}
Plug \eqref{16.28} into \eqref{16.26}, we obtain (we can call it effect Hamiltonian)
\begin{equation}\label{16.32}
    (E-H_0-\lambda P_0 VP_0 -\lambda^2P_0VP_1\frac{1}{E-H_0-\lambda P_1 V P_0}P_1 V P_0)P_0\ket{n}=0.
\end{equation}
The second term:
\begin{equation}
    H_0P_0\ket{n}=H_0\ket*{n^{(0)}}+\lambda H_0P_0\ket*{n^{(1)}}+\mathcal{O}(\lambda^2).
\end{equation}
\begin{equation}
    \begin{split}
        H_0P_0\ket*{n^{(1)}}&=\sum_{k\in D}E_k^{(0)}\bra*{k^{(0)}}P_0\ket*{n^{(1)}}\ket*{k^{(0)}}\\
        &= \sum_{k\in D}(E_D^{(0)}+\varepsilon_k^{(0)})\bra*{k^{(0)}}P_0\ket*{n^{(1)}}\ket*{k^{(0)}}\\
        &= \sum_{k\in D}\varepsilon_k^{(0)}\bra*{k^{(0)}}P_0\ket*{n^{(1)}}\ket*{k^{(0)}} + E_D^{(0)}P_0 \ket*{n^{(1)}}
    \end{split}
\end{equation}
$\varepsilon_k^{(0)}:=E_k^{(0)}-E_D^{(0)}$ can estimate the difference between eigenvalues in $D$. I think a good choice is to let
\begin{equation}
    \left|\sum_{k\in D}\varepsilon_k^{(0)}\bra*{k^{(0)}}P_0\ket*{n^{(1)}}\ket*{k^{(0)}}\right|^2=\sum_{k\in D}\left(\varepsilon_k^{(0)}\right)^2\left|\bra*{k^{(0)}}P_0\ket*{n^{(1)}}\right|^2
\end{equation}
be possibly the smallest.

Given a shift $\varepsilon$, we want
\begin{equation}
    \frac{\pa}{\pa \varepsilon} \sum_{k\in D}\left(\varepsilon_k^{(0)}+\varepsilon\right)^2\left|\bra*{k^{(0)}}P_0\ket*{n^{(1)}}\right|^2=0.
\end{equation}
So,
\begin{equation}
    \varepsilon=-\frac{\sum\varepsilon_k^{(0)}\left|\bra*{k^{(0)}}P_0\ket*{n^{(1)}}\right|^2}{\sum\left|\bra*{k^{(0)}}P_0\ket*{n^{(1)}}\right|^2}
\end{equation}
In the following, we assume $\varepsilon_k^{(0)}$ satisfies
\begin{equation}
    \sum_{k\in D}\varepsilon_k^{(0)}\left|\bra*{k^{(0)}}P_0\ket*{n^{(1)}}\right|^2=0,
\end{equation}
and
\begin{equation}
    \max_{p,q\in D} |\varepsilon_p^{(0)}-\varepsilon_q^{(0)}|=\max_{p,q\in D} |E_p^{(0)}-E_q^{(0)}|.
\end{equation}
If we want to ignore $\varepsilon_k^{(0)}$ in the first $\lambda$ term, we need
\begin{equation}
    \max_{p,q\in D} |E_p^{(0)}-E_q^{(0)}|=o (\lambda) VP_0\ket{n}.
\end{equation}

The term of $\lambda$ in \eqref{16.32} give us eigen-functions
\begin{equation}
    (E-E_D^{(0)}-\lambda P_0 VP_0)\ket*{n^{(0)}}=0.
\end{equation}
That is 
\begin{equation}
    \det \left(V-\Delta^{(1)}_D I\right)=0,
\end{equation}
with a stroke of eigenkets $\{\ket*{l^{(0)}}\}$.

Then we can follow the same procedure as non-degenerate case.
\begin{equation}
    \Delta^{(1)}_l=\expval*{V}{l^{(0)}}
\end{equation}
\begin{equation}
P_0 \ket*{l_i^{(1)}} 
= \lambda\sum_{j \neq i} \frac{P_0 \ket*{l_j^{(0)}}}{\Delta_j^{(1)} - \Delta_i^{(1)}} 
\; \bra*{l_j^{(0)}} \bigg( V P_1 \frac{1}{E_D^{(0)} - H_0} P_1 V \bigg) \ket*{l_i^{(0)}}
\end{equation}
\begin{equation}
    \Delta_l^{(2)}=\sum_{k\notin D}\frac{| V_{kl} |^2}{E_D^{(0)}-E_k^{(0)}}.
\end{equation}

\subsection{Time-dependent Potentials: The Interact Picture}
Consider a Hamiltonian that can be split into two parts,
\begin{equation}
    H=H_0+V(t),
\end{equation}
where $H_0$ does not contain time explicitly. The problem $V(t)=0$ is assumed to be solved in the sense that the energy eigenkets $\ket{n}$  and the energy eigenvalues $E_n$
defined by
\begin{equation}
    H_0\ket{n}=E_n\ket{n}
\end{equation}
are completely known. Suppose
that at $t = 0$, the state ket of a physical system is given by
\begin{equation}
    \ket{\alpha}=\sum_{n}c_n(0)\ket{n}.
\end{equation}
We wish to find $c_n(t)$ for $t >0$ such that
\begin{equation}
    \ket{\alpha,t_0;t}=\sum_{n}c_n(t)\ee^{-\ii E_n t/\hbar}\ket{n}.
\end{equation}
We now use interaction picture, define
\begin{equation}
    \ket{\alpha,t_0;t}_I=\ee^{\ii H_0 t/\hbar}\ket{\alpha,t_0;t}_S.
\end{equation}
Then any operator under interaction picture can be defined as 
\begin{equation}
    A_I=\ee^{\ii H_0 t/\hbar}A_S\ee^{-\ii H_0 t/\hbar}.
\end{equation}
And now the Schrödinger equation becomes
\begin{equation}
    \ii \hbar \frac{\pa}{\pa t}\ket{\alpha,t_0;t}_I=V_I\ket{\alpha,t_0;t}_I.
\end{equation}
So we have
\begin{equation}
    \ii \hbar \frac{\pa}{\pa t}\braket{n}{\alpha,t_0;t}_I=\sum_{m}\bra{n}V_I\ket{m}\braket{m}{\alpha,t_0;t}_I.
\end{equation}
Using
\begin{equation}
    \bra{n}\ee^{\ii H_0 t/\hbar}V(t)\ee^{-\ii H_0 t/\hbar}\ket{m}=V_{nm}(t)\ee^{\ii (E_n-E_m)t/\hbar},
\end{equation}
and
\begin{equation}
    c_n=\braket{n}{\alpha,t_0;t}_I,
\end{equation}
we have
\begin{equation}
    \ii \hbar \frac{\dd}{\dd t}c_{n}=\sum_{m}V_{nm}\ee^{\ii \omega_{nm}t/\hbar}c_{m}(t),
\end{equation}
where
\begin{equation}
    \omega_{nm}=(E_n-E_m)/\hbar.
\end{equation}
Now we deal the case that $V(t)\ll H_0$. Similar to \eqref{9.14}, 
\begin{equation}
    U_I(t,t_0)=\mathcal{T}\exp\left[\frac{-\ii}{\hbar}\int_{t_0}^{t}\dd{t'}V_I(t')\right].
\end{equation}
if we let 
\begin{equation}
    c_n(t)=c_n^{(0)}+c_n^{(1)}+\dots,
\end{equation}
then,
\begin{equation}
    c_n^{(k)}=\left(\frac{-\ii}{\hbar}\right)^{k}\bra{n}\mathcal{T}\left[\int_{t_0}^{t}\dd{t'}V_I(t')\right]^k\ket{\text{init}}.
\end{equation}
In particular,
\begin{eqnarray}
    &c_n^{(0)}(t)=\delta_{ni}\\
    &c_n^{(1)}(t)=\left(\frac{-\ii}{\hbar}\right)\int_{t_0}^{t}\dd{t'}\ee^{\ii \omega_{ni}t'}V_{ni}(t')\\
    &c_n^{(2)}(t)=\left(\frac{-\ii}{\hbar}\right)^{2}\sum_{m}\int_{t_0}^{t}\dd{t_1}\int_{t_0}^{t_1}\dd{t_2}\ee^{\ii \omega_{nm} t_1}V_{nm}(t_1)\ee^{\ii \omega_{mi}t_2}V_{mi}(t_2)
\end{eqnarray}

In most of system in the real world, other atoms will disturb a specific coherent state, thus we can only consider the leaner term, not to worry time too long that can not fit the time condition.

\subsection{Adiabatic Evolution and Berry Phase}
Consider a parameter dependent Hamiltonian $H(\vec{R})$, and $\vec{R}(t)$ is a slow varying. For each $\vec{R}$, define eigen states:
\begin{equation}
    H(\vec{R})\ket*{\psi_n(\vec{R})}=E(\vec{R})\ket*{\psi_n(\vec{R})}.
\end{equation}
We can write 
\begin{equation}
    \ket{\alpha;t}=\sum_{n}c_n(t)\ee^{\ii \theta_n(t)}\ket*{\psi_n(\vec{R}(t))},
\end{equation}
where
\begin{equation}
    \theta_n(t)=-\int_{t_0}^{t}\dd{t'}E_n(t')/ \hbar.
\end{equation}
We find
\begin{equation}
    \sum_{n}\ee^{\ii \theta_n}\left[\dot{c}_n(t)\ket{n;t}+c_n(t)\frac{\pa}{\pa t}\ket{n;t}\right]=0.
\end{equation}
So,
\begin{equation}
    \dot{c}_m(t)=-\sum_{n}c_n(t)\ee^{\ii [\theta_n(t)-\theta_m(t)]} \bra{m;t}\frac{\pa}{\pa t}\ket{n;t}.
\end{equation}
Since
\begin{equation}
    \bra{n;t}\dot{H}\ket{m;t}=[E_n(t)-E_m(t)]\bra{m;t}\frac{\pa}{\pa t}\ket{n;t},
\end{equation}
so,
\begin{equation}\label{16.70}
    \dot{c}_m(t)=-c_m(t)\bra{m;t}\frac{\pa }{\pa t}\ket{m;t}-\sum_{n}c_n(t)\ee^{\ii (\theta_n-\theta_m)}\frac{\bra{m;t}\dot{H}\ket{n;t}}{E_n-E_m}.
\end{equation}

Now we can apply the adiabatic approximation, which amounts to neglecting
the second term in \eqref{16.70}. Roughly, this means that
\begin{equation}
    \frac{\bra{m;t}\dot{H}\ket{n;t}}{E_n-E_m}\ll \bra{m;t}\frac{\pa }{\pa t}\ket{m;t} \sim\frac{E_m}{\hbar}.
\end{equation}
Let
\begin{equation}
    c_n(t)=\ee^{\ii \gamma_n(t)}c_n(0),\ \gamma_n(t)=\ii \int_{0}^{t}\expval*{\frac{\pa}{\pa t'}}{n;t'}\dd{t'}.
\end{equation}
In other words,
\begin{equation}
    \dot{\gamma}_n(t)=\ii \expval*{\frac{\pa}{\pa t}}{n;t}.
\end{equation}
In replace of derivative $R(t)$,
\begin{equation}
    \nabla_R \gamma_n=\ii \expval*{\nabla_R}{n;\vec{R}}=\mathbf{A}(\mathbf{R}).
\end{equation}

We can find that it is independent from time. So we call it geometrical phase. And $\mathbf{A}(\mathbf{R})$ is called Berry connection.

\begin{equation}
    \gamma_n=\oint \mathbf{A}\cdot\dd{\mathbf{R}}=\iint_S \mathbf{B}\cdot \dd{\mathbf{S}}.
\end{equation}
Where 
\begin{equation}
    \mathbf{B}=\nabla_\mathbf{R} \times \mathbf{A}.
\end{equation}

We now multiply $\ket{n;t}$ by  an arbitrary phase phase factor that changes through $\mathbf{R}$-space:
\begin{equation}
    \ket{n;t}\longrightarrow \ee^{\ii \delta(\mathbf{R})}\ket{n;t}.
\end{equation} 
Then 
\begin{equation}
    \tilde{A}_n(\mathbf{R})=\mathbf{A}_n(\mathbf{R})-\nabla_\mathbf{R}\delta(\mathbf{R}),
\end{equation}
\begin{equation}
    \tilde{\mathbf{B}}=\mathbf{B}.
\end{equation}

For further calculation, we derive another form of $\mathbf{B}_n(\mathbf{R})$.
\begin{equation}
    \mathbf{B}_n(\mathbf{R})=\ii \left[\nabla_\mathbf{R}\bra{n;t}\right]\times \left[\nabla_\mathbf{R}\ket{n;t}\right]=\ii \sum_{n\neq m }\left[\nabla_\mathbf{R}\bra{n;t}\right]\ket{m;t}\times \bra{m;t}\left[\nabla_\mathbf{R}\ket{n;t}\right].
\end{equation}
Since 
\begin{equation}
    \bra{m;t}\left[\nabla_\mathbf{R}\ket{n;t}\right]=\frac{\bra{m;t}\left[\nabla_\mathbf{R} H\right]\ket{n;t}}{E_n-E_m},\ n\neq m,
\end{equation}
we have
\begin{equation}
    \mathbf{B}_n(\mathbf{R})=\ii \sum_{m\neq n}\frac{\bra{n;t}\left[\nabla_\mathbf{R} H\right]\ket{m;t}\times\bra{m;t}\left[\nabla_\mathbf{R} H\right]\ket{n;t}}{(E_n-E_m)^2}
\end{equation}
\section{Path Integral}
\subsection{Propagators}
One has
\begin{equation}
    \begin{split}
        \bra{\mathbf{x}}\ket{\alpha,t_0;t}&=\bra{\mathbf{x}}\exp\left[\frac{-\ii H (t-t_0)}{\hbar}\right]\ket{\alpha,t_0}\\
        &=\int \dd{\mathbf{x}'} \bra{\mathbf{x}}\exp\left[\frac{-\ii H (t-t_0)}{\hbar}\right]\ket{\mathbf{x}'}\bra{\mathbf{x}'}\ket{\alpha,t_0}.
    \end{split}
\end{equation}
Let 
\begin{equation}
    K(\mathbf{x},t;\mathbf{x}',t_0)=\bra{\mathbf{x}}\exp\left[\frac{-\ii H (t-t_0)}{\hbar}\right]\ket{\mathbf{x}'},
\end{equation}
then,
\begin{equation}
    \psi(\mathbf{x},t)=\int \dd{\mathbf{x}'} K(\mathbf{x},t;\mathbf{x}',t_0)\psi(\mathbf{x}',t_0).
\end{equation}
We call $K(\mathbf{x},t;\mathbf{x}',t_0)$ the propagator, it connects the wave functions at $t$ and $t_0$.
It is easy to know that
\begin{equation}
    \lim_{t\rightarrow t_0}K(\mathbf{x},t;\mathbf{x}',t_0)=\delta(\mathbf{x}-\mathbf{x}').
\end{equation}

Let us consider a free particle in one dimension as an example.
\begin{equation}
    K(x,t;x',t_0)=\frac{1}{2\pi \hbar} \int_{-\infty}^{+\infty}\dd{p'} \exp\left[ \frac{\ii p'(x-x') }{\hbar}-\frac{\ii p'^2(t-t_0)}{2m\hbar}\right].
\end{equation}
The result is\footnote{We need to deal with a integral in the form of $\int_{x\in \mathbb{R}}\exp (\pm \ii \alpha x^2)\dd{x}= \sqrt{\frac{\pi }{\alpha}}\exp(\pm \ii \pi/4)$. See \href{https://en.wikipedia.org/wiki/Fresnel_integral}{Fresnel integral}. Usually, it can be written as $\sqrt{\frac{\pi}{\mp \ii \alpha}}$.}. 
\begin{equation}\label{17.6}
    K(x,t;x',t_0)=\sqrt{\frac{m}{2\pi \ii \hbar (t-t_0)}}\exp \left[ \frac{\ii m (x-x')^2}{ 2\hbar (t-t_0)}\right].
\end{equation}
\subsection{Propagator as a Transition Amplitude}
In Heisenberg picture, the propagator can also be written as 
\begin{equation}
    \begin{split}
        K(\mathbf{x},t;\mathbf{x}',t_0)&=\bra{\mathbf{x}}\exp\left(\frac{-\ii H t}{\hbar}\right)\exp\left(\frac{\ii H t_0}{\hbar}\right)\ket{\mathbf{x}'}\\
        &=\braket{\mathbf{x},t}{\mathbf{x'},t_0}.
    \end{split}
\end{equation}
It is the amplitude for the particle to go from a space-time point $(\mathbf{x},t)$ to $(\mathbf{x}',t_0)$.

Because at any given time the position kets in the Heisenberg picture
form a complete set, it is legitimate to insert the identity operator written as
\begin{equation}
    \int \dd{\mathbf{x'}} \ket{\mathbf{x'},t'}\bra{\mathbf{x'},t'}=1.
\end{equation}
Clearly, we can divide the time interval into as many smaller sub-intervals as we wish.
\subsection{Feynman’s Formulation}
    Without loss of generality we restrict ourselves to one-dimensional problems.
    \begin{equation}
        \begin{split}
            \braket{x_N,t_N}{x_1,t_1}=&\int \dd{x_{N-1}}\int \dd{x_{N-2}}\cdots \int \dd{x_2} \braket{x_N,t_N}{x_{N-1},t_{N-1}}\\
            & \times \braket{x_{N-1},t_{N-1}}{x_{N-2},t_{N-2}}\cdots \braket{x_2,t_2}{x_1,t_1}.
        \end{split}
    \end{equation}

    Let us make some correspondence between the classical and quantum formalism. We shall know from \eqref{17.6} that
    \begin{equation}
        \exp\left[\ii \int_{t_1}^{t_2} \frac{L_{\text{classical}}(x,\dot{x})\dd{t}}{\hbar}\right]\sim \braket{x_2,t_2}{x_1,t_1}.
    \end{equation}
    Denote
    \begin{equation}
        S(n,n-1):=\int_{t_{n-1}}^{t_n}L_{\text{classical}}(x,\dot{x})\dd{t}.
    \end{equation}
    We multiple this kind of expressions
    \begin{equation}
        \prod_{i=2}^{N}\exp\left[\frac{\ii S(n,n-1)}{\hbar}\right]=\exp\left[\left(\frac{\ii}{\hbar}\sum_{n=2}{N}S(n,n-1)\right)\right]=\exp\left[\frac{\ii S(N,1)}{\hbar}\right].
    \end{equation}
    This does not yet give $\braket{x_N,t_N}{x_1,t_1}$; rather, this equation is the contribution. We must still
    integrate over $x_2,x_3,\cdots,x_{N-1}$. At the same time, exploiting the composition property, we let the time interval between $t_{n-1}$ and $t_n$ be infinitesimally small. 
    Thus, we can feel that 
    \begin{equation}
        \braket{x_N,t_N}{x_1,t_1}\sim \sum_{\text{all paths}} \exp\left[\frac{\ii S(N,1)}{\hbar}\right].
    \end{equation}

\end{document}